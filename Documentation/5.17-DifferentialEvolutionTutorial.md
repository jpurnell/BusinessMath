# Differential Evolution Tutorial

Complete guide to using Differential Evolution optimization in BusinessMath.

## Table of Contents

- [Quick Start](#quick-start)
- [What is Differential Evolution?](#what-is-differential-evolution)
- [Choosing a Mutation Strategy](#choosing-a-mutation-strategy)
- [Parameter Tuning](#parameter-tuning)
- [Real-World Examples](#real-world-examples)
- [GPU Acceleration](#gpu-acceleration)
- [Performance Comparison](#performance-comparison)
- [Troubleshooting](#troubleshooting)

## Quick Start

Copy this into an Xcode Playground to get started immediately:

```swift
import BusinessMath

// Simple 2D optimization problem
let optimizer = DifferentialEvolution<VectorN<Double>>(
    config: .default,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Minimize Rosenbrock function: f(x,y) = (1-x)² + 100(y-x²)²
// Known minimum at (1, 1) with value 0
let rosenbrock = { (v: VectorN<Double>) -> Double in
    let x = v[0], y = v[1]
    return (1.0 - x) * (1.0 - x) + 100.0 * (y - x * x) * (y - x * x)
}

let result = try! optimizer.minimize(rosenbrock, from: VectorN([0.0, 0.0]))

print("Solution: [\(result.solution[0]), \(result.solution[1])]")
print("Objective value: \(result.value)")
print("Converged: \(result.converged)")
// Solution: [0.999, 0.998]
// Objective value: 0.0001
// Converged: true
```

## What is Differential Evolution?

Differential Evolution (DE) is a population-based optimization algorithm that creates new candidate solutions by combining existing ones using vector differences. It's particularly effective for:

- **Continuous optimization** problems
- **Multimodal landscapes** (many local optima)
- **Non-differentiable** functions
- **Noisy** objective functions

### How It Works

1. **Initialize**: Create random population in search space
2. **Mutation**: For each individual, create mutant using vector differences
3. **Crossover**: Mix mutant with target to create trial vector
4. **Selection**: Keep trial if better than target

### Key Advantages

- Simple, few parameters to tune
- Robust across many problem types
- Self-adapting through evolution
- No gradient information needed

## Choosing a Mutation Strategy

Differential Evolution offers three mutation strategies. Choose based on your problem characteristics:

### Strategy 1: rand/1 (Default)

**Best for**: General-purpose optimization, exploration-heavy problems

```swift
import BusinessMath

let config = DifferentialEvolutionConfig(
    strategy: .rand1  // mutant = r1 + F × (r2 - r3)
)

let optimizer = DifferentialEvolution<VectorN<Double>>(
    config: config,
    searchSpace: [(-5.0, 5.0), (-5.0, 5.0)]
)

// Rastrigin function: highly multimodal
let rastrigin = { (v: VectorN<Double>) -> Double in
    let A = 10.0
    let n = 2.0
    var sum = A * n
    for i in 0..<2 {
        let xi = v[i]
        sum += xi * xi - A * cos(2.0 * .pi * xi)
    }
    return sum
}

let result = try! optimizer.minimize(rastrigin, from: VectorN([0.0, 0.0]))
print("Rastrigin minimum: \(result.value)")  // Should be near 0
```

### Strategy 2: best/1

**Best for**: Fast convergence when you're confident about global optimum location

```swift
import BusinessMath

let config = DifferentialEvolutionConfig(
    populationSize: 50,
    generations: 100,
    mutationFactor: 0.8,
    crossoverRate: 0.9,
    strategy: .best1  // mutant = best + F × (r1 - r2)
)

let optimizer = DifferentialEvolution<VectorN<Double>>(
    config: config,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Sphere function: unimodal, smooth
let sphere = { (v: VectorN<Double>) -> Double in v.dot(v) }

let result = try! optimizer.minimize(sphere, from: VectorN([5.0, 5.0]))
print("Sphere minimum: \(result.value)")  // Should be near 0
print("Iterations: \(result.generations)")
```

### Strategy 3: currentToBest1

**Best for**: Balanced exploration/exploitation, difficult landscapes

```swift
import BusinessMath

let config = DifferentialEvolutionConfig(
    populationSize: 60,
    generations: 150,
    mutationFactor: 0.7,
    crossoverRate: 0.95,
    strategy: .currentToBest1  // mutant = current + F×(best-current) + F×(r1-r2)
)

let optimizer = DifferentialEvolution<VectorN<Double>>(
    config: config,
    searchSpace: [(-5.0, 5.0), (-5.0, 5.0)]
)

// Ackley function: many local minima
let ackley = { (v: VectorN<Double>) -> Double in
    let x = v[0], y = v[1]
    let sum1 = x * x + y * y
    let sum2 = cos(2.0 * .pi * x) + cos(2.0 * .pi * y)
    return -20.0 * exp(-0.2 * sqrt(sum1 / 2.0)) - exp(sum2 / 2.0) + 20.0 + exp(1.0)
}

let result = try! optimizer.minimize(ackley, from: VectorN([0.0, 0.0]))
print("Ackley minimum: \(result.value)")  // Should be near 0
```

## Parameter Tuning

### Mutation Factor (F)

Controls the amplification of differential variation:

```swift
import BusinessMath

// Conservative (F = 0.5): Small steps, slow but stable
let conservativeConfig = DifferentialEvolutionConfig(
    mutationFactor: 0.5,
    crossoverRate: 0.9
)

// Aggressive (F = 0.9): Large steps, fast but may overshoot
let aggressiveConfig = DifferentialEvolutionConfig(
    mutationFactor: 0.9,
    crossoverRate: 0.9
)

// Standard (F = 0.8): Recommended starting point
let standardConfig = DifferentialEvolutionConfig.default
```

### Crossover Rate (CR)

Controls mixing between trial and target vectors:

```swift
import BusinessMath

// Low CR (0.5): More conservative, preserves parent structure
let lowCR = DifferentialEvolutionConfig(
    mutationFactor: 0.8,
    crossoverRate: 0.5
)

// High CR (0.95): More exploration, disrupts parent structure
let highCR = DifferentialEvolutionConfig(
    mutationFactor: 0.8,
    crossoverRate: 0.95
)

let optimizer = DifferentialEvolution<VectorN<Double>>(
    config: highCR,
    searchSpace: [(-10.0, 10.0)]
)

let parabola = { (v: VectorN<Double>) -> Double in
    let x = v[0]
    return (x - 3.0) * (x - 3.0)
}

let result = try! optimizer.minimize(parabola, from: VectorN([0.0]))
print("Solution: x = \(result.solution[0])")  // Should be near 3.0
```

### Population Size

Larger populations explore more thoroughly but cost more evaluations:

```swift
import BusinessMath

// Small population: Fast, good for simple problems
let smallPop = DifferentialEvolutionConfig(
    populationSize: 20,
    generations: 50
)

// Large population: Thorough, good for complex problems
let largePop = DifferentialEvolutionConfig(
    populationSize: 100,
    generations: 200
)

// GPU-optimized: Enables GPU acceleration
let gpuPop = DifferentialEvolutionConfig(
    populationSize: 1000,
    generations: 100
)
```

## Real-World Examples

### Example 1: Portfolio Optimization

Optimize portfolio weights to maximize Sharpe ratio:

```swift
import BusinessMath

// Historical returns for 3 assets
let returns = [
    [0.10, 0.12, 0.08],  // Asset 1
    [0.15, -0.05, 0.20], // Asset 2
    [0.08, 0.09, 0.10]   // Asset 3
]

// Calculate mean returns and covariance
let meanReturns = [0.10, 0.10, 0.09]
let riskFreeRate = 0.03

let optimizer = DifferentialEvolution<VectorN<Double>>(
    config: DifferentialEvolutionConfig(
        populationSize: 50,
        generations: 100
    ),
    searchSpace: [(0.0, 1.0), (0.0, 1.0), (0.0, 1.0)]
)

// Negative Sharpe ratio (we minimize)
let negativeSharpe = { (weights: VectorN<Double>) -> Double in
    // Normalize weights to sum to 1
    let w = weights.toArray()
    let sum = w.reduce(0.0, +)
    let normalized = w.map { $0 / sum }

    // Portfolio return
    let portfolioReturn = zip(normalized, meanReturns).map(*).reduce(0.0, +)

    // Simplified portfolio variance (diagonal approximation)
    let portfolioVariance = zip(normalized, normalized).map(*).reduce(0.0, +) * 0.04
    let portfolioStd = sqrt(portfolioVariance)

    // Sharpe ratio
    let sharpe = (portfolioReturn - riskFreeRate) / portfolioStd

    return -sharpe  // Minimize negative Sharpe
}

// Add constraint: weights sum to 1
let sumToOne = MultivariateConstraint<VectorN<Double>>.equality { w in
    w.toArray().reduce(0.0, +) - 1.0
}

let result = try! optimizer.minimize(
    negativeSharpe,
    from: VectorN([0.33, 0.33, 0.34]),
    constraints: [sumToOne]
)

print("Optimal weights:")
let weights = result.solution.toArray()
let sum = weights.reduce(0.0, +)
for (i, w) in weights.enumerated() {
    print("  Asset \(i+1): \(String(format: "%.1f%%", (w/sum)*100))")
}
print("Sharpe ratio: \(String(format: "%.3f", -result.value))")
```

### Example 2: Hyperparameter Tuning

Optimize machine learning hyperparameters:

```swift
import BusinessMath

// Simulate ML model validation error as function of hyperparameters
// In reality, you'd train/validate an actual model
let optimizer = DifferentialEvolution<VectorN<Double>>(
    config: DifferentialEvolutionConfig(
        populationSize: 40,
        generations: 50,
        seed: 42  // Reproducible results
    ),
    searchSpace: [
        (0.0001, 0.1),     // Learning rate
        (0.0, 1.0),        // Dropout rate
        (16.0, 256.0)      // Batch size (continuous, will round)
    ]
)

let validationError = { (hyperparams: VectorN<Double>) -> Double in
    let learningRate = hyperparams[0]
    let dropoutRate = hyperparams[1]
    let batchSize = round(hyperparams[2])

    // Simulated validation error (lower is better)
    // Real implementation would train model and return actual validation error
    let error = abs(learningRate - 0.01) * 10.0 +
                abs(dropoutRate - 0.3) * 2.0 +
                abs(batchSize - 64.0) / 100.0

    return error
}

let result = try! optimizer.minimize(validationError, from: VectorN([0.01, 0.5, 128.0]))

print("Optimal hyperparameters:")
print("  Learning rate: \(String(format: "%.4f", result.solution[0]))")
print("  Dropout rate: \(String(format: "%.2f", result.solution[1]))")
print("  Batch size: \(Int(round(result.solution[2])))")
print("  Validation error: \(String(format: "%.4f", result.value))")
```

### Example 3: Engineering Design

Optimize beam dimensions to minimize weight while meeting stress constraints:

```swift
import BusinessMath

let optimizer = DifferentialEvolution<VectorN<Double>>(
    config: DifferentialEvolutionConfig(
        populationSize: 50,
        generations: 100
    ),
    searchSpace: [
        (10.0, 100.0),  // Width (mm)
        (10.0, 100.0)   // Height (mm)
    ]
)

// Material properties
let density = 7850.0  // Steel (kg/m³)
let length = 2.0      // Beam length (m)
let maxStress = 200e6 // Maximum allowable stress (Pa)
let appliedLoad = 10000.0  // Applied load (N)

// Objective: Minimize weight
let weight = { (dimensions: VectorN<Double>) -> Double in
    let width = dimensions[0] / 1000.0   // Convert mm to m
    let height = dimensions[1] / 1000.0
    let area = width * height
    return density * area * length  // Weight in kg
}

// Constraint: Stress must not exceed allowable
let stressConstraint = MultivariateConstraint<VectorN<Double>>.inequality { dimensions in
    let width = dimensions[0] / 1000.0
    let height = dimensions[1] / 1000.0

    // Moment of inertia
    let I = (width * height * height * height) / 12.0

    // Maximum bending moment
    let M = appliedLoad * length / 4.0

    // Maximum stress
    let stress = (M * (height / 2.0)) / I

    // Constraint: stress - maxStress ≤ 0
    return stress - maxStress
}

let result = try! optimizer.minimize(
    weight,
    from: VectorN([50.0, 50.0]),
    constraints: [stressConstraint]
)

print("Optimal beam dimensions:")
print("  Width: \(String(format: "%.1f", result.solution[0])) mm")
print("  Height: \(String(format: "%.1f", result.solution[1])) mm")
print("  Weight: \(String(format: "%.2f", result.value)) kg")
```

## GPU Acceleration

Differential Evolution automatically uses GPU acceleration for large populations:

### Automatic GPU Activation

```swift
import BusinessMath

// Small population: Runs on CPU
let cpuOptimizer = DifferentialEvolution<VectorN<Double>>(
    config: DifferentialEvolutionConfig(
        populationSize: 100  // CPU (faster for small populations)
    ),
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Large population: Automatically uses GPU
let gpuOptimizer = DifferentialEvolution<VectorN<Double>>(
    config: DifferentialEvolutionConfig(
        populationSize: 1000  // GPU automatically activated
    ),
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Or use the high-performance preset
let fastOptimizer = DifferentialEvolution<VectorN<Double>>(
    config: .highPerformance,  // 1000 population, 500 generations
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

let sphere = { (v: VectorN<Double>) -> Double in v.dot(v) }
let result = try! fastOptimizer.minimize(sphere, from: VectorN([5.0, 5.0]))
print("GPU-accelerated result: \(result.value)")
```

### Checking GPU Availability

```swift
import BusinessMath

#if canImport(Metal)
import Metal

if let device = MTLCreateSystemDefaultDevice() {
    print("GPU available: \(device.name)")
    print("GPU acceleration will be used for populations ≥ 1000")
} else {
    print("GPU not available - will use CPU")
}
#else
print("Metal not supported on this platform")
#endif

// Optimization will work regardless of GPU availability
let optimizer = DifferentialEvolution<VectorN<Double>>(
    config: .highPerformance,
    searchSpace: [(-5.0, 5.0)]
)

let simple = { (v: VectorN<Double>) -> Double in v[0] * v[0] }
let result = try! optimizer.minimize(simple, from: VectorN([2.0]))
print("Result: \(result.value)")
```

## Performance Comparison

### Strategy Comparison

Test all three strategies on the same problem:

```swift
import BusinessMath

let searchSpace = [(-5.0, 5.0), (-5.0, 5.0)]

// Rosenbrock: a challenging test function
let rosenbrock = { (v: VectorN<Double>) -> Double in
    let x = v[0], y = v[1]
    return (1.0 - x) * (1.0 - x) + 100.0 * (y - x * x) * (y - x * x)
}

// Test rand/1
let rand1 = DifferentialEvolution<VectorN<Double>>(
    config: DifferentialEvolutionConfig(strategy: .rand1, seed: 42),
    searchSpace: searchSpace
)
let result1 = try! rand1.minimize(rosenbrock, from: VectorN([0.0, 0.0]))

// Test best/1
let best1 = DifferentialEvolution<VectorN<Double>>(
    config: DifferentialEvolutionConfig(strategy: .best1, seed: 42),
    searchSpace: searchSpace
)
let result2 = try! best1.minimize(rosenbrock, from: VectorN([0.0, 0.0]))

// Test currentToBest1
let ctb1 = DifferentialEvolution<VectorN<Double>>(
    config: DifferentialEvolutionConfig(strategy: .currentToBest1, seed: 42),
    searchSpace: searchSpace
)
let result3 = try! ctb1.minimize(rosenbrock, from: VectorN([0.0, 0.0]))

print("Strategy Comparison on Rosenbrock:")
print("  rand/1: \(String(format: "%.6f", result1.value)) in \(result1.iterations) iterations")
print("  best/1: \(String(format: "%.6f", result2.value)) in \(result2.iterations) iterations")
print("  currentToBest1: \(String(format: "%.6f", result3.value)) in \(result3.iterations) iterations")
```

### CPU vs GPU Benchmark

```swift
import BusinessMath
import Foundation

let searchSpace = Array(repeating: (-5.0, 5.0), count: 10)

let sphere = { (v: VectorN<Double>) -> Double in v.dot(v) }

// CPU benchmark
let cpuConfig = DifferentialEvolutionConfig(
    populationSize: 100,
    generations: 100,
    seed: 42
)
let cpuOptimizer = DifferentialEvolution<VectorN<Double>>(
    config: cpuConfig,
    searchSpace: searchSpace
)

let cpuStart = Date()
let cpuResult = try! cpuOptimizer.minimize(sphere, from: VectorN(Array(repeating: 2.0, count: 10)))
let cpuTime = Date().timeIntervalSince(cpuStart)

// GPU benchmark
let gpuConfig = DifferentialEvolutionConfig(
    populationSize: 1000,
    generations: 100,
    seed: 42
)
let gpuOptimizer = DifferentialEvolution<VectorN<Double>>(
    config: gpuConfig,
    searchSpace: searchSpace
)

let gpuStart = Date()
let gpuResult = try! gpuOptimizer.minimize(sphere, from: VectorN(Array(repeating: 2.0, count: 10)))
let gpuTime = Date().timeIntervalSince(gpuStart)

print("Performance Comparison (10D Sphere):")
print("CPU (100 pop): \(String(format: "%.3f", cpuTime))s, result: \(String(format: "%.6f", cpuResult.value))")
print("GPU (1000 pop): \(String(format: "%.3f", gpuTime))s, result: \(String(format: "%.6f", gpuResult.value))")
if cpuTime > 0 {
    print("Speedup: \(String(format: "%.1fx", cpuTime / gpuTime))")
}
```

## Troubleshooting

### Problem: Slow Convergence

**Symptoms**: Many generations but poor improvement

**Solutions**:
```swift
import BusinessMath

// 1. Increase mutation factor for more exploration
let config1 = DifferentialEvolutionConfig(
    mutationFactor: 0.9,  // Higher = more exploration
    crossoverRate: 0.9
)

// 2. Increase population size
let config2 = DifferentialEvolutionConfig(
    populationSize: 100,  // More diversity
    generations: 200
)

// 3. Try different strategy
let config3 = DifferentialEvolutionConfig(
    strategy: .currentToBest1  // Better balance
)
```

### Problem: Premature Convergence

**Symptoms**: Converges quickly to suboptimal solution

**Solutions**:
```swift
import BusinessMath

// 1. Lower mutation factor
let config1 = DifferentialEvolutionConfig(
    mutationFactor: 0.5,  // Smaller steps
    crossoverRate: 0.7
)

// 2. Increase population diversity
let config2 = DifferentialEvolutionConfig(
    populationSize: 150,  // Larger population
    strategy: .rand1      // More exploratory
)
```

### Problem: Constraint Violations

**Symptoms**: Result doesn't satisfy constraints

**Solutions**:
```swift
import BusinessMath

// 1. Verify constraint formulation (should be ≤ 0 for inequality)
let goodConstraint = MultivariateConstraint<VectorN<Double>>.inequality { v in
    v[0] + v[1] - 10.0  // Correct: x + y ≤ 10 → x + y - 10 ≤ 0
}

// 2. Increase generations to allow convergence
let config = DifferentialEvolutionConfig(
    populationSize: 100,
    generations: 500  // More time to satisfy constraints
)

// 3. Check search space includes feasible region
let feasibleSpace = [
    (0.0, 5.0),  // Ensure constraints can be satisfied
    (0.0, 5.0)
]
```

### Problem: Non-Reproducible Results

**Symptoms**: Different results on each run

**Solutions**:
```swift
import BusinessMath

// Set a seed for deterministic results
let config = DifferentialEvolutionConfig(
    populationSize: 50,
    generations: 100,
    seed: 12345  // Fixed seed
)

// Create separate optimizer instances for reproducible results
// (RNG state persists across minimize() calls on same instance)
let optimizer1 = DifferentialEvolution<VectorN<Double>>(
    config: config,
    searchSpace: [(-10.0, 10.0)]
)

let optimizer2 = DifferentialEvolution<VectorN<Double>>(
    config: config,
    searchSpace: [(-10.0, 10.0)]
)

// Now results are reproducible
let result1 = try! optimizer1.minimize({ v in v[0] * v[0] }, from: VectorN([5.0]))
let result2 = try! optimizer2.minimize({ v in v[0] * v[0] }, from: VectorN([5.0]))

print("Result 1: \(result1.value.number(6))")
print("Result 2: \(result2.value.number(6))")
// Both should be identical

// Alternative: Reuse optimizer for different problems
// (but results won't match previous runs due to RNG state)
let optimizer = DifferentialEvolution<VectorN<Double>>(
    config: config,
    searchSpace: [(-10.0, 10.0)]
)
let problem1 = try! optimizer.minimize({ v in v[0] * v[0] }, from: VectorN([5.0]))
let problem2 = try! optimizer.minimize({ v in v[0] * v[0] * v[0] }, from: VectorN([5.0]))
```

## Further Reading

- Original DE paper: Storn & Price (1997)
- Strategy comparison: Das & Suganthan (2011)
- See `DifferentialEvolution.swift` for implementation details
- GPU acceleration: `GPU_ACCELERATION_TUTORIAL.md`
