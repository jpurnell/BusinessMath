# Particle Swarm Optimization Tutorial

Complete guide to using Particle Swarm Optimization in BusinessMath.

## Table of Contents

- [Quick Start](#quick-start)
- [What is Particle Swarm Optimization?](#what-is-particle-swarm-optimization)
- [Understanding PSO Parameters](#understanding-pso-parameters)
- [Parameter Tuning](#parameter-tuning)
- [Real-World Examples](#real-world-examples)
- [GPU Acceleration](#gpu-acceleration)
- [Performance Comparison](#performance-comparison)
- [Troubleshooting](#troubleshooting)

## Quick Start

Copy this into an Xcode Playground to get started immediately:

```swift
import BusinessMath

// Simple 2D optimization problem
let optimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: .default,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Minimize sphere function: f(x,y) = x² + y²
// Known minimum at (0, 0) with value 0
let sphere = { (v: VectorN<Double>) -> Double in v.dot(v) }

let result = try! optimizer.minimize(sphere, from: VectorN([5.0, 5.0]))

print("Solution: [\(result.solution[0]), \(result.solution[1])]")
print("Objective value: \(result.value)")
print("Iterations: \(result.iterations)")
// Solution: [0.002, -0.001]
// Objective value: 0.000005
// Iterations: 42
```

## What is Particle Swarm Optimization?

Particle Swarm Optimization (PSO) is inspired by social behavior of bird flocking and fish schooling. Each "particle" represents a candidate solution that moves through the search space influenced by:

1. **Personal experience**: Its own best-found position
2. **Social knowledge**: The swarm's global best position
3. **Momentum**: Its current velocity

### How It Works

Each particle updates its velocity and position using:

**Velocity Update:**
```
v = w×v + c₁×r₁×(pbest - x) + c₂×r₂×(gbest - x)
```

Where:
- `w` = inertia weight (momentum)
- `c₁` = cognitive coefficient (personal attraction)
- `c₂` = social coefficient (swarm attraction)
- `r₁, r₂` = random values in [0,1]

**Position Update:**
```
x = x + v
```

### Key Advantages

- Fast convergence on smooth landscapes
- Simple implementation, few parameters
- No gradient information needed
- Naturally handles continuous variables
- Self-organizing swarm behavior

## Understanding PSO Parameters

### Standard PSO 2011 Parameters

BusinessMath uses Standard PSO 2011 parameters by default:

```swift
import BusinessMath

let config = ParticleSwarmConfig.default

print("Inertia weight (w): \(config.inertiaWeight)")       // 0.7298
print("Cognitive coeff (c1): \(config.cognitiveCoefficient)")  // 1.49618
print("Social coeff (c2): \(config.socialCoefficient)")     // 1.49618
print("Swarm size: \(config.swarmSize)")                    // 50
print("Max iterations: \(config.maxIterations)")            // 100

// These are proven values from research
// Use them unless you have specific reasons to change
```

### Creating Custom Configurations

```swift
import BusinessMath

// Custom configuration for your specific problem
let customConfig = ParticleSwarmConfig(
    swarmSize: 30,           // Number of particles
    maxIterations: 200,      // Maximum iterations
    inertiaWeight: 0.8,      // Momentum (0.4-0.9)
    cognitiveCoefficient: 2.0,  // Personal best attraction
    socialCoefficient: 2.0,   // Global best attraction
    velocityClamp: 0.2,      // Max velocity as fraction of range
    seed: 42                 // For reproducible results
)

let optimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: customConfig,
    searchSpace: [(-5.0, 5.0), (-5.0, 5.0)]
)
```

## Parameter Tuning

### Inertia Weight (w)

Controls exploration vs. exploitation balance:

```swift
import BusinessMath

// High inertia (0.9): More exploration, slower convergence
let exploratoryConfig = ParticleSwarmConfig(
    swarmSize: 40,
    maxIterations: 100,
    inertiaWeight: 0.9,  // High momentum
    cognitiveCoefficient: 1.5,
    socialCoefficient: 1.5
)

let exploratoryOptimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: exploratoryConfig,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Rastrigin: highly multimodal, needs exploration
let rastrigin = { (v: VectorN<Double>) -> Double in
    let A = 10.0
    var sum = A * 2.0
    for i in 0..<2 {
        let xi = v[i]
        sum += xi * xi - A * cos(2.0 * .pi * xi)
    }
    return sum
}

let result1 = try! exploratoryOptimizer.minimize(rastrigin, from: VectorN([0.0, 0.0]))
print("High inertia result: \(result1.value)")


// Low inertia (0.4): More exploitation, faster convergence
let exploitativeConfig = ParticleSwarmConfig(
    swarmSize: 40,
    maxIterations: 100,
    inertiaWeight: 0.4,  // Low momentum
    cognitiveCoefficient: 1.5,
    socialCoefficient: 1.5,
    seed: 42
)

let exploitativeOptimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: exploitativeConfig,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Sphere: unimodal, benefits from exploitation
let sphere = { (v: VectorN<Double>) -> Double in v.dot(v) }

let result2 = try! exploitativeOptimizer.minimize(sphere, from: VectorN([5.0, 5.0]))
print("Low inertia result: \(result2.value)")
```

### Cognitive vs. Social Balance

```swift
import BusinessMath

// Cognitive-heavy (c1 > c2): Independent exploration
let cognitiveConfig = ParticleSwarmConfig(
    swarmSize: 40,
    maxIterations: 80,
    inertiaWeight: 0.7,
    cognitiveCoefficient: 2.5,  // Strong personal attraction
    socialCoefficient: 1.0,      // Weak swarm attraction
    seed: 42
)

let cognitiveOptimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: cognitiveConfig,
    searchSpace: [(-5.0, 5.0), (-5.0, 5.0)]
)


// Social-heavy (c2 > c1): Fast convergence
let socialConfig = ParticleSwarmConfig(
    swarmSize: 40,
    maxIterations: 80,
    inertiaWeight: 0.7,
    cognitiveCoefficient: 1.0,   // Weak personal attraction
    socialCoefficient: 2.5,       // Strong swarm attraction
    seed: 42
)

let socialOptimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: socialConfig,
    searchSpace: [(-5.0, 5.0), (-5.0, 5.0)]
)

let rosenbrock = { (v: VectorN<Double>) -> Double in
    let x = v[0], y = v[1]
    return (1.0 - x) * (1.0 - x) + 100.0 * (y - x * x) * (y - x * x)
}

let cogResult = try! cognitiveOptimizer.minimize(rosenbrock, from: VectorN([0.0, 0.0]))
let socResult = try! socialOptimizer.minimize(rosenbrock, from: VectorN([0.0, 0.0]))

print("Cognitive-heavy: \(cogResult.value) in \(cogResult.iterations) iterations")
print("Social-heavy: \(socResult.value) in \(socResult.iterations) iterations")
```

### Velocity Clamping

Prevent velocity explosion:

```swift
import BusinessMath

// No clamping: Can lead to particles shooting out of bounds
let noClampConfig = ParticleSwarmConfig(
    swarmSize: 30,
    maxIterations: 50,
    velocityClamp: nil,  // No velocity limit
    seed: 42
)

// Conservative clamping: Safer but slower
let conservativeConfig = ParticleSwarmConfig(
    swarmSize: 30,
    maxIterations: 50,
    velocityClamp: 0.1,  // 10% of range per step
    seed: 42
)

// Standard clamping: Recommended
let standardConfig = ParticleSwarmConfig(
    swarmSize: 30,
    maxIterations: 50,
    velocityClamp: 0.2,  // 20% of range per step (default)
    seed: 42
)

let optimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: standardConfig,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

let ackley = { (v: VectorN<Double>) -> Double in
    let x = v[0], y = v[1]
    let sum1 = x * x + y * y
    let sum2 = cos(2.0 * .pi * x) + cos(2.0 * .pi * y)
    return -20.0 * exp(-0.2 * sqrt(sum1 / 2.0)) - exp(sum2 / 2.0) + 20.0 + exp(1.0)
}

let result = try! optimizer.minimize(ackley, from: VectorN([0.0, 0.0]))
print("Clamped PSO result: \(result.value)")
```

### Swarm Size

```swift
import BusinessMath

// Small swarm: Fast, good for simple problems
let smallSwarm = ParticleSwarmConfig(
    swarmSize: 20,
    maxIterations: 100
)

// Medium swarm: Balanced (recommended)
let mediumSwarm = ParticleSwarmConfig.default  // 50 particles

// Large swarm: Better exploration, more evaluations
let largeSwarm = ParticleSwarmConfig(
    swarmSize: 100,
    maxIterations: 100
)

// GPU swarm: Enables GPU acceleration
let gpuSwarm = ParticleSwarmConfig.highPerformance  // 1000 particles

let searchSpace = [(- 10.0, 10.0), (-10.0, 10.0)]
let sphere = { (v: VectorN<Double>) -> Double in v.dot(v) }

// Test different swarm sizes
let smallOpt = ParticleSwarmOptimization<VectorN<Double>>(
    config: smallSwarm,
    searchSpace: searchSpace
)
let smallResult = try! smallOpt.minimize(sphere, from: VectorN([5.0, 5.0]))

let mediumOpt = ParticleSwarmOptimization<VectorN<Double>>(
    config: mediumSwarm,
    searchSpace: searchSpace
)
let mediumResult = try! mediumOpt.minimize(sphere, from: VectorN([5.0, 5.0]))

print("Small swarm (20): \(smallResult.value)")
print("Medium swarm (50): \(mediumResult.value)")
```

## Real-World Examples

### Example 1: Antenna Design

Optimize antenna parameters for maximum gain:

```swift
import BusinessMath

let optimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: ParticleSwarmConfig(
        swarmSize: 50,
        maxIterations: 150,
        seed: 42
    ),
    searchSpace: [
        (0.1, 2.0),   // Element length (wavelengths)
        (0.1, 1.0),   // Element spacing (wavelengths)
        (0.0, 180.0)  // Phase shift (degrees)
    ]
)

// Simplified antenna gain model (negative because we minimize)
let negativeGain = { (params: VectorN<Double>) -> Double in
    let length = params[0]
    let spacing = params[1]
    let phase = params[2] * .pi / 180.0  // Convert to radians

    // Simplified gain calculation (real would use EM simulation)
    let gainFactor = sin(2.0 * .pi * length) *
                    cos(2.0 * .pi * spacing) *
                    (1.0 + cos(phase))

    return -abs(gainFactor)  // Minimize negative gain
}

// Constraint: Physical spacing must be reasonable
let spacingConstraint = MultivariateConstraint<VectorN<Double>>.inequality { params in
    let spacing = params[1]
    return 0.25 - spacing  // spacing ≥ 0.25
}

let result = try! optimizer.minimize(
    negativeGain,
    from: VectorN([1.0, 0.5, 90.0]),
    constraints: [spacingConstraint]
)

print("Optimal antenna design:")
print("  Length: \(String(format: "%.3f", result.solution[0])) λ")
print("  Spacing: \(String(format: "%.3f", result.solution[1])) λ")
print("  Phase: \(String(format: "%.1f", result.solution[2]))°")
print("  Gain: \(String(format: "%.3f", -result.value))")
```

### Example 2: Chemical Process Optimization

Optimize reactor conditions for maximum yield:

```swift
import BusinessMath

let optimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: ParticleSwarmConfig(
        swarmSize: 60,
        maxIterations: 100,
        inertiaWeight: 0.8,
        seed: 42
    ),
    searchSpace: [
        (50.0, 150.0),   // Temperature (°C)
        (1.0, 10.0),     // Pressure (atm)
        (0.1, 2.0),      // Catalyst concentration (mol/L)
        (10.0, 120.0)    // Residence time (min)
    ]
)

// Simplified yield model (real would be from experimental data)
let negativeYield = { (conditions: VectorN<Double>) -> Double in
    let temp = conditions[0]
    let pressure = conditions[1]
    let catalyst = conditions[2]
    let time = conditions[3]

    // Simplified Arrhenius-like model
    let optimalTemp = 100.0
    let optimalPressure = 5.0
    let optimalCatalyst = 1.0
    let optimalTime = 60.0

    let tempFactor = exp(-0.01 * (temp - optimalTemp) * (temp - optimalTemp))
    let pressureFactor = exp(-0.1 * (pressure - optimalPressure) * (pressure - optimalPressure))
    let catalystFactor = catalyst / (1.0 + catalyst)
    let timeFactor = time / (10.0 + time)

    let yield = tempFactor * pressureFactor * catalystFactor * timeFactor * 100.0

    return -yield  // Minimize negative yield
}

// Safety constraint: Temperature and pressure limits
let safetyConstraint = MultivariateConstraint<VectorN<Double>>.inequality { conditions in
    let temp = conditions[0]
    let pressure = conditions[1]

    // Safety limit: temp × pressure ≤ 800
    return (temp * pressure) - 800.0
}

let result = try! optimizer.minimize(
    negativeYield,
    from: VectorN([100.0, 5.0, 1.0, 60.0]),
    constraints: [safetyConstraint]
)

print("Optimal process conditions:")
print("  Temperature: \(String(format: "%.1f", result.solution[0]))°C")
print("  Pressure: \(String(format: "%.1f", result.solution[1])) atm")
print("  Catalyst: \(String(format: "%.2f", result.solution[2])) mol/L")
print("  Time: \(String(format: "%.1f", result.solution[3])) min")
print("  Yield: \(String(format: "%.1f", -result.value))%")
```

### Example 3: Neural Network Training

Optimize neural network weights (small network):

```swift
import BusinessMath

// Simple 2-2-1 neural network (2 inputs, 2 hidden, 1 output)
// 2×2 + 2 + 2×1 + 1 = 9 weights total

let optimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: ParticleSwarmConfig(
        swarmSize: 40,
        maxIterations: 200,
        inertiaWeight: 0.7,
        seed: 42
    ),
    searchSpace: Array(repeating: (-5.0, 5.0), count: 9)  // 9 weights
)

// Training data for XOR problem
let trainingData = [
    ([0.0, 0.0], 0.0),
    ([0.0, 1.0], 1.0),
    ([1.0, 0.0], 1.0),
    ([1.0, 1.0], 0.0)
]

// Mean squared error
let mse = { (weights: VectorN<Double>) -> Double in
    let w = weights.toArray()

    // Extract weights
    let w1 = [[w[0], w[1]], [w[2], w[3]]]  // Input to hidden
    let b1 = [w[4], w[5]]                   // Hidden bias
    let w2 = [w[6], w[7]]                   // Hidden to output
    let b2 = w[8]                           // Output bias

    // Sigmoid activation
    func sigmoid(_ x: Double) -> Double {
        return 1.0 / (1.0 + exp(-x))
    }

    var totalError = 0.0
    for (inputs, target) in trainingData {
        // Forward pass
        let h1 = sigmoid(w1[0][0] * inputs[0] + w1[0][1] * inputs[1] + b1[0])
        let h2 = sigmoid(w1[1][0] * inputs[0] + w1[1][1] * inputs[1] + b1[1])
        let output = sigmoid(w2[0] * h1 + w2[1] * h2 + b2)

        // Error
        let error = target - output
        totalError += error * error
    }

    return totalError / Double(trainingData.count)
}

let result = try! optimizer.minimize(mse, from: VectorN(Array(repeating: 0.0, count: 9)))

print("Neural network training results:")
print("  Final MSE: \(String(format: "%.6f", result.value))")
print("  Iterations: \(result.iterations)")

// Test the trained network
let w = result.solution.toArray()
func predict(_ input: [Double]) -> Double {
    let w1 = [[w[0], w[1]], [w[2], w[3]]]
    let b1 = [w[4], w[5]]
    let w2 = [w[6], w[7]]
    let b2 = w[8]

    func sigmoid(_ x: Double) -> Double { 1.0 / (1.0 + exp(-x)) }

    let h1 = sigmoid(w1[0][0] * input[0] + w1[0][1] * input[1] + b1[0])
    let h2 = sigmoid(w1[1][0] * input[0] + w1[1][1] * input[1] + b1[1])
    return sigmoid(w2[0] * h1 + w2[1] * h2 + b2)
}

print("\nXOR predictions:")
for (inputs, expected) in trainingData {
    let prediction = predict(inputs)
    print("  \(inputs) → \(String(format: "%.3f", prediction)) (expected: \(expected))")
}
```

### Example 4: Supply Chain Optimization

Optimize inventory levels across multiple locations:

```swift
import BusinessMath

// 3 warehouses, optimize stock levels
let optimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: ParticleSwarmConfig(
        swarmSize: 50,
        maxIterations: 100,
        seed: 42
    ),
    searchSpace: [
        (0.0, 1000.0),  // Warehouse 1 stock
        (0.0, 1000.0),  // Warehouse 2 stock
        (0.0, 1000.0)   // Warehouse 3 stock
    ]
)

// Cost parameters
let holdingCostPerUnit = [2.0, 2.5, 1.8]     // $/unit/day
let orderCost = [100.0, 120.0, 90.0]         // $/order
let stockoutCost = 50.0                       // $/unit
let avgDailyDemand = [50.0, 60.0, 40.0]      // units/day
let demandStdDev = [10.0, 12.0, 8.0]         // units/day

// Total cost function
let totalCost = { (stockLevels: VectorN<Double>) -> Double in
    let stock = stockLevels.toArray()

    var cost = 0.0

    for i in 0..<3 {
        // Holding cost
        let holdingCost = stock[i] * holdingCostPerUnit[i]

        // Ordering cost (simplified EOQ-based)
        let orderFrequency = avgDailyDemand[i] * 30.0 / max(stock[i], 1.0)
        let monthlOrderCost = orderCost[i] * orderFrequency

        // Stockout risk cost (if stock < safety stock)
        let safetyStock = avgDailyDemand[i] * 2.0 + demandStdDev[i] * 2.0
        let stockoutRisk = max(0.0, safetyStock - stock[i])
        let stockoutCostTotal = stockoutRisk * stockoutCost * 0.1

        cost += holdingCost + monthlyOrderCost + stockoutCostTotal
    }

    return cost
}

// Constraint: Total stock limited by warehouse capacity
let capacityConstraint = MultivariateConstraint<VectorN<Double>>.inequality { stock in
    let total = stock.toArray().reduce(0.0, +)
    return total - 2500.0  // Total capacity: 2500 units
}

let result = try! optimizer.minimize(
    totalCost,
    from: VectorN([500.0, 500.0, 500.0]),
    constraints: [capacityConstraint]
)

print("Optimal inventory levels:")
for i in 0..<3 {
    print("  Warehouse \(i+1): \(Int(result.solution[i])) units")
}
print("Total monthly cost: $\(String(format: "%.2f", result.value))")
print("Total inventory: \(Int(result.solution.toArray().reduce(0.0, +))) units")
```

## GPU Acceleration

PSO automatically uses GPU acceleration for large swarms:

### Automatic GPU Activation

```swift
import BusinessMath

// Small swarm: Runs on CPU
let cpuOptimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: ParticleSwarmConfig(
        swarmSize: 100  // CPU (faster for small swarms)
    ),
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Large swarm: Automatically uses GPU
let gpuOptimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: ParticleSwarmConfig(
        swarmSize: 1000  // GPU automatically activated
    ),
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Or use the high-performance preset
let fastOptimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: .highPerformance,  // 1000 particles, 500 iterations
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

let sphere = { (v: VectorN<Double>) -> Double in v.dot(v) }
let result = try! fastOptimizer.minimize(sphere, from: VectorN([5.0, 5.0]))
print("GPU-accelerated result: \(result.value)")
```

### Checking GPU Availability

```swift
import BusinessMath

#if canImport(Metal)
import Metal

if let device = MTLCreateSystemDefaultDevice() {
    print("GPU available: \(device.name)")
    print("GPU acceleration will be used for swarms ≥ 1000")
} else {
    print("GPU not available - will use CPU")
}
#else
print("Metal not supported on this platform")
#endif

// Optimization will work regardless of GPU availability
let optimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: .highPerformance,
    searchSpace: [(-5.0, 5.0)]
)

let simple = { (v: VectorN<Double>) -> Double in v[0] * v[0] }
let result = try! optimizer.minimize(simple, from: VectorN([2.0]))
print("Result: \(result.value)")
```

## Performance Comparison

### Swarm Size Impact

```swift
import BusinessMath
import Foundation

let searchSpace = Array(repeating: (-5.0, 5.0), count: 10)
let sphere = { (v: VectorN<Double>) -> Double in v.dot(v) }

// Small swarm
let smallConfig = ParticleSwarmConfig(
    swarmSize: 30,
    maxIterations: 100,
    seed: 42
)
let smallOpt = ParticleSwarmOptimization<VectorN<Double>>(
    config: smallConfig,
    searchSpace: searchSpace
)

let smallStart = Date()
let smallResult = try! smallOpt.minimize(sphere, from: VectorN(Array(repeating: 2.0, count: 10)))
let smallTime = Date().timeIntervalSince(smallStart)

// Large swarm (GPU)
let largeConfig = ParticleSwarmConfig(
    swarmSize: 1000,
    maxIterations: 100,
    seed: 42
)
let largeOpt = ParticleSwarmOptimization<VectorN<Double>>(
    config: largeConfig,
    searchSpace: searchSpace
)

let largeStart = Date()
let largeResult = try! largeOpt.minimize(sphere, from: VectorN(Array(repeating: 2.0, count: 10)))
let largeTime = Date().timeIntervalSince(largeStart)

print("Performance Comparison (10D Sphere):")
print("CPU (30 particles): \(String(format: "%.3f", smallTime))s, result: \(String(format: "%.6f", smallResult.value))")
print("GPU (1000 particles): \(String(format: "%.3f", largeTime))s, result: \(String(format: "%.6f", largeResult.value))")
if smallTime > 0 {
    let speedup = (smallTime / largeTime) * (1000.0 / 30.0)  // Normalize for swarm size
    print("GPU speedup: \(String(format: "%.1fx", speedup))")
}
```

### Convergence Analysis

```swift
import BusinessMath

let optimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: ParticleSwarmConfig(
        swarmSize: 50,
        maxIterations: 100,
        seed: 42
    ),
    searchSpace: [(-5.0, 5.0), (-5.0, 5.0)]
)

let rosenbrock = { (v: VectorN<Double>) -> Double in
    let x = v[0], y = v[1]
    return (1.0 - x) * (1.0 - x) + 100.0 * (y - x * x) * (y - x * x)
}

let result = try! optimizer.optimizeDetailed(objective: rosenbrock)

print("Convergence History:")
print("  Initial best: \(String(format: "%.6f", result.convergenceHistory.first!))")
print("  Final best: \(String(format: "%.6f", result.convergenceHistory.last!))")
print("  Iterations: \(result.iterations)")
print("  Converged: \(result.converged)")
print("  Reason: \(result.convergenceReason)")

// Print every 10th iteration
for i in stride(from: 0, to: result.convergenceHistory.count, by: 10) {
    let fitness = result.convergenceHistory[i]
    print("  Iteration \(i): \(String(format: "%.6f", fitness))")
}
```

## Troubleshooting

### Problem: Premature Convergence

**Symptoms**: Swarm converges quickly to suboptimal solution, diversity collapses

**Solutions**:
```swift
import BusinessMath

// 1. Increase inertia weight for more exploration
let config1 = ParticleSwarmConfig(
    inertiaWeight: 0.9,  // Higher momentum
    cognitiveCoefficient: 1.5,
    socialCoefficient: 1.5
)

// 2. Increase swarm size for more diversity
let config2 = ParticleSwarmConfig(
    swarmSize: 100,  // More particles
    maxIterations: 200
)

// 3. Balance cognitive/social components
let config3 = ParticleSwarmConfig(
    cognitiveCoefficient: 2.0,  // Increase personal exploration
    socialCoefficient: 1.5       // Reduce swarm influence
)
```

### Problem: Slow Convergence

**Symptoms**: Many iterations but poor improvement

**Solutions**:
```swift
import BusinessMath

// 1. Decrease inertia for faster convergence
let config1 = ParticleSwarmConfig(
    inertiaWeight: 0.4,  // Lower momentum
    cognitiveCoefficient: 2.0,
    socialCoefficient: 2.0
)

// 2. Increase social component
let config2 = ParticleSwarmConfig(
    cognitiveCoefficient: 1.5,
    socialCoefficient: 2.5  // Stronger swarm attraction
)

// 3. Reduce velocity clamping
let config3 = ParticleSwarmConfig(
    velocityClamp: 0.5  // Allow larger steps
)
```

### Problem: Particles Escaping Bounds

**Symptoms**: Particles move outside search space

**Solutions**:
```swift
import BusinessMath

// 1. Enable or tighten velocity clamping
let config1 = ParticleSwarmConfig(
    velocityClamp: 0.2  // Limit to 20% of range per step
)

// 2. Lower inertia weight
let config2 = ParticleSwarmConfig(
    inertiaWeight: 0.5  // Reduce momentum
)

// Note: Particles are automatically clamped to search space bounds
// But velocity clamping prevents large oscillations
```

### Problem: Constraint Violations

**Symptoms**: Final solution doesn't satisfy constraints

**Solutions**:
```swift
import BusinessMath

// 1. Increase iterations to allow convergence
let config = ParticleSwarmConfig(
    swarmSize: 60,
    maxIterations: 500  // More time for constrained optimization
)

// 2. Verify constraint formulation
let goodConstraint = MultivariateConstraint<VectorN<Double>>.inequality { v in
    v[0] + v[1] - 10.0  // Correct: x + y ≤ 10 → x + y - 10 ≤ 0
}

// 3. Ensure search space includes feasible region
let feasibleSpace = [
    (0.0, 5.0),  // Make sure constraints can be satisfied
    (0.0, 5.0)
]
```

### Problem: Non-Reproducible Results

**Symptoms**: Different results on each run

**Solutions**:
```swift
import BusinessMath

// Set a seed for deterministic results
let config = ParticleSwarmConfig(
    swarmSize: 50,
    maxIterations: 100,
    seed: 12345  // Fixed seed
)

let optimizer = ParticleSwarmOptimization<VectorN<Double>>(
    config: config,
    searchSpace: [(-10.0, 10.0)]
)

// Now results are reproducible
let result1 = try! optimizer.minimize({ v in v[0] * v[0] }, from: VectorN([5.0]))
let result2 = try! optimizer.minimize({ v in v[0] * v[0] }, from: VectorN([5.0]))

print("Result 1: \(result1.value)")
print("Result 2: \(result2.value)")
// Both should be identical
```

## Further Reading

- Original PSO paper: Kennedy & Eberhart (1995)
- Standard PSO 2011: Bratton & Kennedy (2007)
- See `ParticleSwarmOptimization.swift` for implementation details
- GPU acceleration: `GPU_ACCELERATION_TUTORIAL.md`
