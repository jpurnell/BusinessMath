# Monte Carlo Performance Guide

Learn how to optimize Monte Carlo simulations for maximum performance.

## Overview

This guide explains the performance characteristics of Monte Carlo simulations in BusinessMath, covering:
- When to use GPU acceleration
- Understanding GPU vs CPU trade-offs
- CPU optimization techniques (Ziggurat algorithm)
- Performance benchmarking

## GPU Acceleration

### When GPU Helps

GPU acceleration provides the best speedup for:

1. **Complex Models** (10+ operations per iteration)
   - Financial models with multiple calculations
   - Models with many mathematical operations
   - Typical speedup: **5-15x**

2. **Very Large Simulations** (1M+ iterations)
   - Long-running simulations where setup cost amortizes
   - Complex models with massive iteration counts
   - Typical speedup: **Up to 20x**

### When GPU Doesn't Help

GPU overhead dominates performance for:

1. **Simple Models** (2-5 operations)
   - Basic addition, subtraction
   - Minimal computation per iteration
   - Typical speedup: **Only 2-3x**

2. **Small Simulations** (< 10K iterations)
   - GPU automatically disabled for < 1000 iterations
   - Setup overhead exceeds computation time

### GPU Overhead Sources

The GPU incurs overhead from:

- **Buffer Allocation**: ~8-10MB for 100K iterations
- **Data Upload**: Distributions and bytecode transfer to GPU
- **Metal Compilation**: One-time cost (~50ms, cached via singleton)
- **Result Download**: Transferring results back to CPU
- **Synchronization**: Waiting for GPU to complete

For simple models, this overhead can be **335x the actual computation time**!

### Example: Good GPU Use Case

```swift
// Complex financial model: multiple operations per iteration
let model = MonteCarloExpressionModel { builder in
    let units = builder[0]
    let price = builder[1]
    let fixedCosts = builder[2]
    let variableCost = builder[3]
    let taxRate = builder[4]

    let revenue = units * price
    let variableCosts = units * variableCost
    let totalCosts = fixedCosts + variableCosts
    let ebit = revenue - totalCosts
    let netIncome = ebit * (1.0 - taxRate)

    return netIncome  // 9 operations per iteration
}

var simulation = MonteCarloSimulation(
    iterations: 500_000,  // Large iteration count
    enableGPU: true,
    expressionModel: model
)

// Expected: 10-15x speedup
```

### Example: Poor GPU Use Case

```swift
// Simple model: only 1 operation
let model = MonteCarloExpressionModel { builder in
    builder[0] + builder[1]  // Just addition
}

var simulation = MonteCarloSimulation(
    iterations: 10_000,  // Small iteration count
    enableGPU: true,
    expressionModel: model
)

// Expected: Only 2x speedup (GPU overhead dominates)
```

## CPU Performance Optimization

### Current Implementation: Box-Muller Transform

The current CPU implementation uses the **Box-Muller transform** for generating normal random numbers:

```
Performance: ~100 CPU cycles per sample
Components:
  - log():   ~40 cycles
  - sqrt():  ~15 cycles
  - cos():   ~50 cycles
  - sin():   ~50 cycles (for second sample)
```

**Overhead**: For simple models, this makes CPU **10x slower than optimal**.

### Future Optimization: Ziggurat Algorithm

The **Ziggurat algorithm** provides 5-10x faster normal random number generation:

#### How Ziggurat Works

1. **Decompose the Bell Curve**: The normal distribution is divided into ~256 horizontal rectangles
2. **Fast Path (98% of samples)**: Simple table lookup + comparison (~10 cycles)
3. **Slow Path (2% of samples)**: Fallback to precise calculations (~120 cycles)
4. **Average Performance**: ~12 cycles per sample

#### Ziggurat vs Box-Muller

| Method | Cycles/Sample | Operations |
|--------|---------------|------------|
| **Box-Muller** (current) | ~100 | 2× log, 1× sqrt, 2× trig |
| **Ziggurat** (future) | ~12 | 1-2 lookups, 1-2 comparisons |
| **Speedup** | **8x faster** | Mostly table lookups |

#### Expected Impact

Implementing Ziggurat would:
- Improve CPU performance from 686ms → ~100ms (for 100K iterations)
- Make GPU vs CPU comparison more balanced (4-5x instead of 1.6x)
- Reduce simple model overhead by 85%

### When to Optimize CPU

CPU optimization is most valuable for:
- Closure-based models (can't use GPU)
- Models with correlations (GPU doesn't support)
- Simple models where GPU overhead dominates
- Cross-platform code (non-Apple hardware)

## Performance Measurement

### Benchmarking Best Practices

1. **Warm-up Run**: First GPU run includes compilation overhead
2. **Multiple Iterations**: Average over 3-5 runs for stability
3. **Realistic Models**: Test with your actual use case
4. **Check GPU Usage**: Verify `results.usedGPU` is true

### Example Benchmark

```swift
import Foundation
import BusinessMath

Task {
    do {
        let model = MonteCarloExpressionModel { builder in
            // Your model here
            builder[0] + builder[1]
        }

        // Warm-up
        var warmupSim = MonteCarloSimulation(iterations: 1000, enableGPU: true, expressionModel: model)
        warmupSim.addInput(SimulationInput(name: "A", distribution: DistributionNormal(100, 10)))
        warmupSim.addInput(SimulationInput(name: "B", distribution: DistributionNormal(50, 5)))
        _ = try warmupSim.run()

        // Measure GPU
        let gpuStart = Date()
        var gpuSim = MonteCarloSimulation(iterations: 100_000, enableGPU: true, expressionModel: model)
        gpuSim.addInput(SimulationInput(name: "A", distribution: DistributionNormal(100, 10)))
        gpuSim.addInput(SimulationInput(name: "B", distribution: DistributionNormal(50, 5)))
        let gpuResults = try gpuSim.run()
        let gpuTime = Date().timeIntervalSince(gpuStart)

        // Measure CPU
        let cpuStart = Date()
        var cpuSim = MonteCarloSimulation(iterations: 100_000, enableGPU: false, expressionModel: model)
        cpuSim.addInput(SimulationInput(name: "A", distribution: DistributionNormal(100, 10)))
        cpuSim.addInput(SimulationInput(name: "B", distribution: DistributionNormal(50, 5)))
        let cpuResults = try cpuSim.run()
        let cpuTime = Date().timeIntervalSince(cpuStart)

        print("Speedup: \(cpuTime / gpuTime)x")
    } catch {
        print("Benchmark failed: \(error)")
    }
}
```

## Performance Summary

| Model Complexity | Iterations | Expected GPU Speedup |
|-----------------|------------|---------------------|
| Simple (2-5 ops) | 10K | No benefit (overhead dominates) |
| Simple (2-5 ops) | 100K+ | 2-3x |
| Complex (10+ ops) | 100K | 5-10x |
| Complex (10+ ops) | 1M+ | 10-20x |

**Key Takeaway**: GPU acceleration shines for complex models with large iteration counts. For simple models, focus on CPU optimization or accept modest GPU speedups.

## See Also

- <doc:4.1-MonteCarloTimeSeriesGuide>
- <doc:4.2-ScenarioAnalysisGuide>
- <doc:4.3-MonteCarloExpressionModelsGuide>
