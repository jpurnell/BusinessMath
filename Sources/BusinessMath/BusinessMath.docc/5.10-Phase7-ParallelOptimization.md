# Phase 7: Parallel Multi-Start Optimization - Complete Tutorial

**Created:** 2025-12-11
**Status:** Complete âœ…

---

## Table of Contents

1. [Overview](#overview)
2. [Quick Start](#quick-start)
3. [How It Works](#how-it-works)
4. [When to Use Parallel Multi-Start](#when-to-use-parallel-multi-start)
5. [Parameter Tuning Guide](#parameter-tuning-guide)
6. [Real-World Examples](#real-world-examples)
7. [Understanding Results](#understanding-results)
8. [Performance Characteristics](#performance-characteristics)
9. [Troubleshooting](#troubleshooting)
10. [Best Practices](#best-practices)

---

## Overview

Parallel Multi-Start Optimization solves a fundamental problem in optimization: **local minima traps**. By running multiple optimization attempts from different random starting points simultaneously, it dramatically increases your chances of finding the global optimum instead of getting stuck in a local minimum.

### What Problems Does It Solve?

**Before Parallel Multi-Start:**
- Single-start optimizers often get trapped in local minima
- No way to know if you found the global optimum or just a local one
- Had to manually try different starting points
- Sequential trials wasted time
- Inconsistent results between runs

**After Parallel Multi-Start:**
- Tries multiple starting points **simultaneously** (true parallelism via async/await)
- Automatically selects the best result across all attempts
- Tracks success rate to understand problem difficulty
- Utilizes all CPU cores for maximum speed
- Repeatable, reliable results

### Key Features

- **True Parallel Execution**: Uses Swift's TaskGroup for concurrent optimization across CPU cores
- **Multiple Algorithm Support**: Gradient Descent, Newton-Raphson, Constrained, Inequality
- **Automatic Best Selection**: Returns the solution with lowest objective value
- **Success Rate Tracking**: Know what percentage of starts converged successfully
- **Starting Point Intelligence**: Tracks which starting point led to best solution
- **100% Test Coverage**: 16 comprehensive tests ensure reliability

---

## Quick Start

### Simplest Possible Use

```swift
import BusinessMath

// Define your objective function
let rosenbrock: @Sendable (VectorN<Double>) -> Double = { v in
    let x = v[0], y = v[1]
    return (1 - x) * (1 - x) + 100 * (y - x*x) * (y - x*x)
}

// Create optimizer
let optimizer = ParallelOptimizer<VectorN<Double>>(
    algorithm: .gradientDescent(learningRate: 0.001),
    numberOfStarts: 10,
    maxIterations: 1000
)

// Optimize from multiple random starts in parallel
// Note: In playgrounds, wrap async code in Task { }
Task {
    let result = try await optimizer.optimize(
        objective: rosenbrock,
        searchRegion: (
            lower: VectorN([-2.0, -2.0]),
            upper: VectorN([2.0, 2.0])
        ),
        constraints: []
    )

    print("Best solution: \(result.solution)")           // Near [1.0, 1.0]
    print("Objective value: \(result.objectiveValue)")   // Near 0.0
    print("Success rate: \(result.successRate)")         // 0.8 (80% converged)
    print("Starts tried: \(result.allResults.count)")    // 10
}
```

That's it! The optimizer:
1. Generated 10 random starting points in [-2, 2] Ã— [-2, 2]
2. Ran 10 gradient descent optimizations **in parallel**
3. Automatically selected the best result
4. Tracked which attempts converged

---

## How It Works

### The Parallel Process

When you call `optimize()`, the Parallel Optimizer:

1. **Generates Random Starting Points**
   ```
   Example: 10 starts in region [-5, 5] Ã— [-5, 5]
   Start 1: [-3.2, 4.1]
   Start 2: [1.7, -2.8]
   Start 3: [-0.5, 3.3]
   ...
   Start 10: [4.2, -1.9]
   ```

2. **Launches Parallel Tasks** (Swift TaskGroup)
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Task 1  â”‚  â”‚ Task 2  â”‚  â”‚ Task 3  â”‚  â”‚ Task 4  â”‚
   â”‚ Core 1  â”‚  â”‚ Core 2  â”‚  â”‚ Core 3  â”‚  â”‚ Core 4  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚            â”‚            â”‚            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                All run simultaneously
   ```

3. **Each Task Optimizes Independently**
   - Uses selected algorithm (Gradient Descent, Newton-Raphson, etc.)
   - Runs until convergence or max iterations
   - Returns solution and convergence status

4. **Collects and Analyzes Results**
   ```
   Start 1: f = 0.12  âœ“ converged
   Start 2: f = 1.47  âœ— failed
   Start 3: f = 0.003 âœ“ converged  â† BEST!
   Start 4: f = 0.21  âœ“ converged
   ...
   ```

5. **Returns Best Result**
   - Solution with lowest objective value
   - Success rate: 7/10 = 70%
   - Which starting point won

### Under the Hood: Swift Concurrency

```swift
// Simplified version of what happens inside
let allResults = try await withThrowingTaskGroup(
    of: (VectorN<Double>, OptimizationResult<VectorN<Double>>).self
) { group in
    for start in startingPoints {
        group.addTask {
            // This runs in parallel!
            let result = try runOptimization(from: start)
            return (start, result)
        }
    }

    // Collect all results
    var results: [(VectorN<Double>, OptimizationResult)] = []
    for try await (start, result) in group {
        results.append((start, result))
    }
    return results
}

// Find best
let best = allResults.min { $0.1.value < $1.1.value }
```

---

## When to Use Parallel Multi-Start

### âœ… Ideal Use Cases

**1. Non-Convex Problems with Multiple Local Minima**
```swift
// Rastrigin function: many local minima
let rastrigin: @Sendable (VectorN<Double>) -> Double = { v in
    let n = Double(v.toArray().count)
    let A = 10.0
    return A * n + v.toArray().reduce(0) { sum, xi in
        sum + (xi * xi - A * cos(2 * .pi * xi))
    }
}

// GOOD: Parallel multi-start will explore many valleys
let optimizer = ParallelOptimizer<VectorN<Double>>(
    algorithm: .gradientDescent(learningRate: 0.01),
    numberOfStarts: 20,  // Try many starts!
    maxIterations: 500
)
```

**2. Unknown Problem Landscape**
- Don't know if problem is convex or has local minima?
- Parallel multi-start gives you confidence you found the best solution
- Success rate tells you problem difficulty

**3. Rosenbrock and Similar "Banana Valley" Problems**
```swift
// Rosenbrock: narrow curved valley - hard to optimize
let rosenbrock: @Sendable (VectorN<Double>) -> Double = { v in
    let x = v[0], y = v[1]
    return (1 - x) * (1 - x) + 100 * (y - x*x) * (y - x*x)
}

// Parallel multi-start handles curved valleys well
```

**4. When You Have Multiple CPU Cores**
- 8-core machine? Use 16-24 starts
- 4-core machine? Use 8-12 starts
- Scales beautifully with hardware

**5. When Result Quality Matters More Than Speed**
- Financial optimization
- Engineering design
- Scientific research
- Any scenario where finding the true optimum is critical

### âŒ When NOT to Use

**1. Simple Convex Problems**
```swift
// Simple quadratic: f(x,y) = xÂ² + yÂ²
// Single start from anywhere converges to (0,0)
// Parallel multi-start is overkill
```

**2. Very Fast Single-Start Optimization**
- If single optimization takes <1ms
- Overhead of parallel coordination might dominate

**3. Extremely Large Problems**
- 1000+ variables
- Memory constraints from running many optimizations simultaneously
- Consider adaptive algorithm selection instead

**4. When You Have a Good Initial Guess**
- If you know the approximate location of the optimum
- Single-start from that guess is more efficient

---

## Parameter Tuning Guide

### Number of Starts

The most important parameter to tune.

```swift
// RULE OF THUMB:
// Conservative: numberOfStarts = 10-20
// Moderate:     numberOfStarts = 20-50
// Aggressive:   numberOfStarts = 50-100
// Overkill:     numberOfStarts = 100+
```

**How to Choose:**

| Problem Type | Recommended Starts | Reasoning |
|-------------|-------------------|-----------|
| 2D problems | 10-20 | Small search space |
| 3-5D problems | 20-30 | Medium search space |
| 6-10D problems | 30-50 | Larger search space |
| Unknown difficulty | 20 | Safe default |
| Known many local minima | 50-100 | Need more coverage |

**Tuning Strategy:**
```swift
// Start conservative
let result1 = try await optimizer.optimize(numberOfStarts: 10, ...)
print("Success rate: \(result1.successRate)")  // e.g., 0.4 (40%)

// If success rate < 0.5, increase starts
let result2 = try await optimizer.optimize(numberOfStarts: 30, ...)
print("Success rate: \(result2.successRate)")  // e.g., 0.7 (70%) - better!

// If success rate > 0.9, you might be using too many
```

### Search Region

Define where to sample starting points.

```swift
// TOO NARROW: might miss global optimum
searchRegion: (
    lower: VectorN([0.9, 0.9]),
    upper: VectorN([1.1, 1.1])
)

// JUST RIGHT: covers likely region
searchRegion: (
    lower: VectorN([-5.0, -5.0]),
    upper: VectorN([5.0, 5.0])
)

// TOO WIDE: wasted effort in irrelevant regions
searchRegion: (
    lower: VectorN([-1000.0, -1000.0]),
    upper: VectorN([1000.0, 1000.0])
)
```

**Best Practice:**
- Start with a wide region (e.g., Â±10 around origin)
- Look at `result.bestStartingPoint` to see where success came from
- Narrow region for second run if needed

### Algorithm Selection

Different algorithms for different problems.

```swift
// GRADIENT DESCENT: General purpose, reliable
.gradientDescent(learningRate: 0.01)
// Best for: Most problems
// Speed: Fast
// Robustness: High

// NEWTON-RAPHSON: Fast convergence when near optimum
.newtonRaphson
// Best for: Smooth problems, near optimum
// Speed: Very fast near optimum
// Robustness: Can fail if Hessian singular

// CONSTRAINED: Equality constraints
.constrained
// Best for: Problems with g(x) = 0 constraints
// Speed: Moderate
// Robustness: Handles constraints

// INEQUALITY: Inequality constraints
.inequality
// Best for: Problems with g(x) â‰¤ 0 constraints
// Speed: Moderate
// Robustness: Handles constraints
```

**Decision Guide:**
```
â”Œâ”€ Start here â”€â”
â”‚ Unconstrained?â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€ Yes â”€â”
       â”‚       â”‚
       â”‚   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   â”‚ Use Gradient â”‚
       â”‚   â”‚  Descent     â”‚
       â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€ No â”€â”€â”
               â”‚
           â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Equality or  â”‚
           â”‚ Inequality?  â”‚
           â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€ Equality â†’ .constrained
               â””â”€ Inequality â†’ .inequality
```

### Learning Rate (for Gradient Descent)

```swift
// PROBLEM SIZE ADAPTIVE:
// 2D problems:     learningRate = 0.05 - 0.1
// 5D problems:     learningRate = 0.01 - 0.05
// 10D problems:    learningRate = 0.001 - 0.01
// 50D+ problems:   learningRate = 0.0001 - 0.001

let dimension = initialGuess.toArray().count
let adaptiveLR = max(0.001, min(0.05, 0.1 / sqrt(Double(dimension))))
```

### Max Iterations

```swift
// CONSERVATIVE (use if time not critical):
maxIterations: 1000

// BALANCED (default recommendation):
maxIterations: 500

// AGGRESSIVE (when you need speed):
maxIterations: 100

// NOTE: Each start uses maxIterations independently
// Total iterations = numberOfStarts Ã— maxIterations
```

---

## Real-World Examples

### Example 1: Portfolio Optimization with Multiple Local Optima

**Problem:** Optimize asset allocation with non-convex risk function.

```swift
import BusinessMath

// Non-convex portfolio risk function
let portfolioRisk: @Sendable (VectorN<Double>) -> Double = { weights in
    // weights: [stock1, stock2, stock3, stock4]

    // Constraint: must sum to 1 (handled separately)
    let sum = weights.toArray().reduce(0, +)
    if abs(sum - 1.0) > 0.01 {
        return 1e10  // Penalty for violating sum constraint
    }

    // Non-convex risk with correlation effects
    let w = weights.toArray()
    var risk = 0.0

    // Variance terms
    let variances = [0.04, 0.09, 0.16, 0.25]  // Individual asset risks
    for i in 0..<4 {
        risk += w[i] * w[i] * variances[i]
    }

    // Non-linear correlation effects (creates local minima)
    risk += 0.5 * w[0] * w[1] * cos(w[0] - w[1])
    risk += 0.3 * w[2] * w[3] * sin(w[2] + w[3])

    return risk
}

// Constraints: each weight in [0, 1], sum = 1
let constraints = [
    MultivariateConstraint<VectorN<Double>>.equality(
        function: { v in v.toArray().reduce(0, +) - 1.0 },
        gradient: nil
    )
]

// Parallel multi-start optimizer
let optimizer = ParallelOptimizer<VectorN<Double>>(
    algorithm: .constrained,  // Handle sum = 1 constraint
    numberOfStarts: 30,       // Many starts for robustness
    maxIterations: 500,
    tolerance: 1e-6
)

Task {
    let result = try await optimizer.optimize(
        objective: portfolioRisk,
        searchRegion: (
            lower: VectorN([0.0, 0.0, 0.0, 0.0]),
            upper: VectorN([1.0, 1.0, 1.0, 1.0])
        ),
        constraints: constraints
    )

    print("Optimal allocation: \(result.solution)")
    print("Minimum risk: \(result.objectiveValue)")
    print("Success rate: \(result.successRate)")
    print("Converged starts: \(result.allResults.filter { $0.converged }.count)/30")

    // Analyze diversity of solutions found
    let objectiveValues = result.allResults.map { $0.value }
    print("Best: \(objectiveValues.min() ?? 0)")
    print("Worst: \(objectiveValues.max() ?? 0)")
    print("Range: \(objectiveValues.max()! - objectiveValues.min()!) (shows problem difficulty)")
}
```

### Example 2: Neural Network Hyperparameter Optimization

**Problem:** Find optimal learning rate and momentum for neural network.

```swift
// Simulate training loss as function of hyperparameters
let trainingLoss: @Sendable (VectorN<Double>) -> Double = { params in
    let learningRate = params[0]  // [0.0001, 0.1]
    let momentum = params[1]       // [0.0, 0.99]

    // Realistic loss landscape with:
    // - Multiple local minima (different training behaviors)
    // - Plateaus (flat regions)
    // - Sharp valleys (optimal regions)

    // Base loss
    var loss = (learningRate - 0.01) * (learningRate - 0.01)
    loss += (momentum - 0.9) * (momentum - 0.9)

    // Add non-convexity (local minima)
    loss += 0.1 * sin(50 * learningRate) * cos(20 * momentum)

    // Penalize extreme values
    if learningRate < 0.0001 || learningRate > 0.1 {
        loss += 100.0
    }
    if momentum < 0.0 || momentum > 0.99 {
        loss += 100.0
    }

    return loss
}

let optimizer = ParallelOptimizer<VectorN<Double>>(
    algorithm: .gradientDescent(learningRate: 0.05),
    numberOfStarts: 40,  // Thorough search
    maxIterations: 300
)

Task {
    let result = try await optimizer.optimize(
        objective: trainingLoss,
        searchRegion: (
            lower: VectorN([0.0001, 0.0]),
            upper: VectorN([0.1, 0.99])
        ),
        constraints: []
    )

    print("Optimal learning rate: \(result.solution[0])")
    print("Optimal momentum: \(result.solution[1])")
    print("Expected validation loss: \(result.objectiveValue)")
    print("Search reliability: \(result.successRate)")
}
```

### Example 3: Chemical Process Optimization

**Problem:** Optimize reactor conditions (temperature, pressure, catalyst ratio) for maximum yield.

```swift
// Process yield as function of conditions
let processYield: @Sendable (VectorN<Double>) -> Double = { conditions in
    let temp = conditions[0]      // Temperature (Â°C): [200, 400]
    let pressure = conditions[1]  // Pressure (bar): [1, 10]
    let catalyst = conditions[2]  // Catalyst ratio: [0.01, 0.2]

    // Yield function with multiple optima (different reaction pathways)
    // We minimize negative yield (to maximize yield)

    // Primary reaction pathway
    let tempDiff1 = (temp - 280) / 40
    let pressDiff1 = (pressure - 5) / 2
    let yield1 = 80.0 * exp(-tempDiff1 * tempDiff1) *
                       exp(-pressDiff1 * pressDiff1) *
                       catalyst / (catalyst + 0.05)

    // Secondary pathway (local optimum)
    let tempDiff2 = (temp - 350) / 30
    let pressDiff2 = (pressure - 8) / 2
    let yield2 = 60.0 * exp(-tempDiff2 * tempDiff2) *
                       exp(-pressDiff2 * pressDiff2) *
                       (0.1 / (catalyst + 0.1))

    // Combined yield (creates multiple local maxima)
    let totalYield = max(yield1, yield2)

    return -totalYield  // Negative because we minimize
}

// Inequality constraints: all values must be positive
let constraints = [
    MultivariateConstraint<VectorN<Double>>.inequality(
        function: { v in -v[0] + 200 },  // temp â‰¥ 200
        gradient: nil
    ),
    MultivariateConstraint<VectorN<Double>>.inequality(
        function: { v in v[0] - 400 },  // temp â‰¤ 400
        gradient: nil
    ),
    MultivariateConstraint<VectorN<Double>>.inequality(
        function: { v in -v[1] + 1 },  // pressure â‰¥ 1
        gradient: nil
    ),
    MultivariateConstraint<VectorN<Double>>.inequality(
        function: { v in v[1] - 10 },  // pressure â‰¤ 10
        gradient: nil
    )
]

let optimizer = ParallelOptimizer<VectorN<Double>>(
    algorithm: .inequality,
    numberOfStarts: 25,
    maxIterations: 400
)

Task {
    let result = try await optimizer.optimize(
        objective: processYield,
        searchRegion: (
            lower: VectorN([200.0, 1.0, 0.01]),
            upper: VectorN([400.0, 10.0, 0.2])
        ),
        constraints: constraints
    )

    print("Optimal temperature: \(result.solution[0])Â°C")
    print("Optimal pressure: \(result.solution[1]) bar")
    print("Optimal catalyst ratio: \(result.solution[2])")
    print("Maximum yield: \(-result.objectiveValue)%")
    print("Process robustness: \(result.successRate)")

    // Analyze alternative optima found
    let allYields = result.allResults.map { -$0.value }  // Convert back to positive
    let sortedYields = allYields.sorted(by: >)
    print("\nTop 5 yields found:")
    for (i, yield_val) in sortedYields.prefix(5).enumerated() {
        print("  \(i+1). \(yield_val)%")
    }
}
```

---

## Understanding Results

### The ParallelOptimizationResult Structure

```swift
public struct ParallelOptimizationResult<V: VectorSpace> {
    /// Whether the best result converged
    public let success: Bool

    /// Best solution found across all starting points
    public let solution: V

    /// Objective value at best solution
    public let objectiveValue: Double

    /// Results from ALL optimization attempts
    public let allResults: [MultivariateOptimizationResult<V>]

    /// Proportion of attempts that converged (0.0 to 1.0)
    public let successRate: Double

    /// Starting point that led to best solution
    public let bestStartingPoint: V
}
```

### Interpreting Success Rate

The success rate tells you about problem difficulty:

```
Success Rate    Interpretation                 Action
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
> 0.9 (90%+)    Very well-behaved problem     Consider reducing numberOfStarts
0.7 - 0.9       Well-behaved problem          Good balance
0.5 - 0.7       Moderately difficult          Current settings OK
0.3 - 0.5       Difficult problem             Increase numberOfStarts
< 0.3 (30%)     Very difficult problem        2-3Ã— more starts, check algorithm choice
```

### Example Analysis

```swift
let result = try await optimizer.optimize(...)

// 1. Check if we found a good solution
if result.success {
    print("âœ“ Best result converged")
} else {
    print("âš ï¸ Best result did not fully converge - but may still be usable")
}

// 2. Understand problem difficulty
let difficulty = result.successRate
switch difficulty {
case 0.9...1.0:
    print("Problem is easy - high success rate")
case 0.5..<0.9:
    print("Problem is moderate difficulty")
case 0.0..<0.5:
    print("Problem is difficult - consider more starts")
default:
    break
}

// 3. Analyze diversity of solutions
let objectives = result.allResults.map { $0.value }
let best = objectives.min() ?? 0
let worst = objectives.max() ?? 0
let range = worst - best

print("Objective range: \(range)")
if range < 0.01 {
    print("â†’ All starts converged to same region (likely global optimum)")
} else if range < 1.0 {
    print("â†’ Some variation but reasonable agreement")
} else {
    print("â†’ Large variation - problem has many local minima")
}

// 4. Check where success came from
print("Best starting point: \(result.bestStartingPoint)")
print("This tells you where in the search region to focus")

// 5. Convergence analysis
let convergedCount = result.allResults.filter { $0.converged }.count
let avgIterations = result.allResults.map { $0.iterations }.reduce(0, +) / result.allResults.count
print("\nConverged: \(convergedCount)/\(result.allResults.count)")
print("Average iterations: \(avgIterations)")
```

### Visualizing Results (Conceptual)

For 2D problems, you can imagine plotting all starting points and their final solutions:

```
Search Region: [-5, 5] Ã— [-5, 5]

Starting Points (â—‹):        Final Solutions (â—):

    â—‹       â—‹       â—‹           â—  â—  â—
 â—‹      â—‹       â—‹               â—  â—
    â—‹       â—‹                      â—  â—
 â—‹      â—‹       â—‹               â—  â—
    â—‹       â—‹       â—‹           â—  â—  â—

Random starts across         Most converged to
entire region               same global optimum (â—)
                            A few stuck in local
                            minimum at different â—
```

---

## Performance Characteristics

### Execution Time

**Serial vs Parallel Speedup:**

```
Number of    Serial Time    Parallel Time    Speedup
Cores        (10 starts)    (10 starts)      Factor
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1            10 seconds     10 seconds       1Ã—
2            10 seconds     5 seconds        2Ã—
4            10 seconds     2.5 seconds      4Ã—
8            10 seconds     1.3 seconds      7.7Ã—
16           10 seconds     0.7 seconds      14.3Ã—

Note: Actual speedup depends on:
- Objective function complexity
- Operating system overhead
- Memory bandwidth
```

**Practical Timing Examples:**

```swift
// Fast objective (1ms per evaluation):
// 10 starts Ã— 100 iterations Ã— 1ms = 1 second total
// On 4 cores: ~250ms

// Medium objective (10ms per evaluation):
// 20 starts Ã— 500 iterations Ã— 10ms = 100 seconds total
// On 8 cores: ~12.5 seconds

// Expensive objective (100ms per evaluation):
// 50 starts Ã— 1000 iterations Ã— 100ms = 5000 seconds total
// On 16 cores: ~312 seconds (5 minutes)
```

### Memory Usage

```
Per optimization:
- VectorN storage: ~8 bytes Ã— dimensions
- Gradient storage: ~8 bytes Ã— dimensions
- Hessian (Newton-Raphson): ~8 bytes Ã— dimensionsÂ²

Total memory = numberOfStarts Ã— per-optimization

Example (10D problem, 20 starts, Newton-Raphson):
- Solutions: 20 Ã— 10 Ã— 8 = 1.6 KB
- Gradients: 20 Ã— 10 Ã— 8 = 1.6 KB
- Hessians: 20 Ã— 100 Ã— 8 = 16 KB
Total: ~20 KB (negligible)

Even with 1000 starts: ~1 MB (still small)
```

### Scaling Recommendations

```
Problem Size    Recommended Cores    Recommended Starts    Expected Time
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2D, fast        2-4 cores           10-20                 < 1 second
2D, slow        4-8 cores           10-20                 1-10 seconds
5D, moderate    4-8 cores           20-30                 10-60 seconds
10D, moderate   8-16 cores          30-50                 1-5 minutes
20D, expensive  16+ cores           50-100                5-30 minutes
```

---

## Troubleshooting

### Problem: Low Success Rate (< 30%)

**Symptoms:**
```swift
result.successRate  // 0.2 (20%)
```

**Possible Causes & Solutions:**

1. **Algorithm not suitable for problem**
   ```swift
   // Try different algorithm
   // From: .gradientDescent(learningRate: 0.01)
   // To:   .newtonRaphson  (faster convergence)
   ```

2. **Learning rate too large (diverging)**
   ```swift
   // Reduce learning rate
   .gradientDescent(learningRate: 0.001)  // Was 0.1
   ```

3. **Too few iterations**
   ```swift
   // Increase max iterations
   maxIterations: 2000  // Was 500
   ```

4. **Search region contains infeasible points**
   ```swift
   // Narrow search region to feasible area
   searchRegion: (
       lower: VectorN([0.1, 0.1]),  // Was [-10, -10]
       upper: VectorN([5.0, 5.0])   // Was [10, 10]
   )
   ```

### Problem: All Starts Find Different Solutions

**Symptoms:**
```swift
let objectives = result.allResults.map { $0.value }
let range = objectives.max()! - objectives.min()!  // Large value (> 10)
```

**This usually means:**
- Problem has many local minima (expected for hard problems)
- Search region too wide
- You're actually finding different valid solutions

**Solutions:**
```swift
// 1. Increase number of starts to find best
numberOfStarts: 100  // Was 20

// 2. Narrow search region if you know approximate location
searchRegion: (lower: VectorN([0, 0]), upper: VectorN([2, 2]))

// 3. Accept that problem is difficult
// Use the best result with confidence
print("Best of \(result.allResults.count) attempts: \(result.objectiveValue)")
```

### Problem: Takes Too Long

**Symptoms:**
- Optimization doesn't complete in reasonable time

**Solutions:**

1. **Reduce number of starts**
   ```swift
   numberOfStarts: 10  // Was 50
   ```

2. **Reduce max iterations**
   ```swift
   maxIterations: 200  // Was 1000
   ```

3. **Use faster algorithm**
   ```swift
   // Gradient descent is usually faster than Newton-Raphson
   .gradientDescent(learningRate: 0.01)
   ```

4. **Narrow search region**
   ```swift
   // Smaller region = faster convergence
   searchRegion: (
       lower: VectorN([0.5, 0.5]),  // Was [-10, -10]
       upper: VectorN([1.5, 1.5])   // Was [10, 10]
   )
   ```

### Problem: Objective Value is Inf or NaN

**Symptoms:**
```swift
result.objectiveValue  // inf or nan
```

**Causes:**
1. Objective function returns inf/nan for some inputs
2. Search region includes invalid points
3. Numerical overflow in calculations

**Solutions:**
```swift
// Add bounds checking to objective
let safeObjective: @Sendable (VectorN<Double>) -> Double = { v in
    let x = v[0], y = v[1]

    // Check bounds
    guard x.isFinite && y.isFinite else {
        return 1e10  // Large penalty
    }

    // Compute objective
    let value = yourFunction(x, y)

    // Return finite value
    return value.isFinite ? value : 1e10
}
```

### Problem: Best Starting Point is on Boundary

**Symptoms:**
```swift
result.bestStartingPoint  // [searchRegion.lower[0], searchRegion.lower[1]]
```

**Interpretation:**
- Optimum might be outside your search region!

**Solution:**
```swift
// Expand search region in that direction
searchRegion: (
    lower: VectorN([-20.0, -20.0]),  // Was [-10, -10]
    upper: VectorN([10.0, 10.0])     // Keep upper same
)
```

---

## Best Practices

### 1. Start Conservative, Scale Up

```swift
// Run 1: Quick exploration
let quick = ParallelOptimizer<VectorN<Double>>(
    algorithm: .gradientDescent(learningRate: 0.01),
    numberOfStarts: 10,
    maxIterations: 100
)
let quickResult = try await quick.optimize(...)
print("Quick success rate: \(quickResult.successRate)")

// If success rate < 0.5, run more thorough optimization
if quickResult.successRate < 0.5 {
    let thorough = ParallelOptimizer<VectorN<Double>>(
        algorithm: .gradientDescent(learningRate: 0.01),
        numberOfStarts: 50,
        maxIterations: 500
    )
    let thoroughResult = try await thorough.optimize(...)
    return thoroughResult
}
return quickResult
```

### 2. Use Success Rate as Quality Metric

```swift
func optimize_with_quality_guarantee(
    objective: @Sendable @escaping (VectorN<Double>) -> Double,
    searchRegion: (VectorN<Double>, VectorN<Double>),
    minimumSuccessRate: Double = 0.7
) async throws -> ParallelOptimizationResult<VectorN<Double>> {

    var starts = 10
    while starts <= 100 {
        let optimizer = ParallelOptimizer<VectorN<Double>>(
            algorithm: .gradientDescent(learningRate: 0.01),
            numberOfStarts: starts,
            maxIterations: 500
        )

        let result = try await optimizer.optimize(
            objective: objective,
            searchRegion: searchRegion,
            constraints: []
        )

        if result.successRate >= minimumSuccessRate {
            print("âœ“ Achieved \(result.successRate) success rate with \(starts) starts")
            return result
        }

        print("âš ï¸ Success rate \(result.successRate) below target, increasing starts...")
        starts *= 2
    }

    throw OptimizationError.failedToConverge(
        message: "Could not achieve \(minimumSuccessRate) success rate"
    )
}
```

### 3. Analyze Result Distribution

```swift
extension ParallelOptimizationResult {
    func analyzeResults() {
        let objectives = allResults.map { $0.value }
        let converged = allResults.filter { $0.converged }

        print("â•â•â• Parallel Optimization Analysis â•â•â•")
        print("Total starts: \(allResults.count)")
        print("Converged: \(converged.count) (\(successRate * 100)%)")
        print("")

        print("Objective values:")
        print("  Best:    \(objectives.min() ?? 0)")
        print("  Worst:   \(objectives.max() ?? 0)")
        print("  Median:  \(objectives.sorted()[objectives.count / 2])")
        print("  Range:   \(objectives.max()! - objectives.min()!)")
        print("")

        print("Convergence:")
        let avgIters = allResults.map { $0.iterations }.reduce(0, +) / allResults.count
        print("  Average iterations: \(avgIters)")
        print("")

        print("Best starting point: \(bestStartingPoint)")
        print("Best solution: \(solution)")
        print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    }
}

// Usage:
let result = try await optimizer.optimize(...)
result.analyzeResults()
```

### 4. Validate Result with Single-Start Near Best

```swift
// After parallel optimization, verify by running single optimization
// from near the best starting point

let parallelResult = try await parallelOptimizer.optimize(...)

// Single-start verification near best starting point
let verifyOptimizer = MultivariateGradientDescent<VectorN<Double>>(
    learningRate: 0.01,
    maxIterations: 1000,
    tolerance: 1e-8  // Stricter tolerance
)

let verifyResult = try verifyOptimizer.minimize(
    function: objective,
    gradient: { v in try numericalGradient(objective, at: v) },
    initialGuess: parallelResult.bestStartingPoint
)

print("Parallel result: \(parallelResult.objectiveValue)")
print("Verification:    \(verifyResult.value)")
print("Difference:      \(abs(parallelResult.objectiveValue - verifyResult.value))")

if abs(parallelResult.objectiveValue - verifyResult.value) < 0.001 {
    print("âœ“ Result verified - high confidence in global optimum")
}
```

### 5. Use Constraints Wisely

```swift
// GOOD: Use search region for box constraints
// Instead of:
let badConstraints = [
    MultivariateConstraint<VectorN<Double>>.inequality(
        function: { v in v[0] - 1.0 },  // x â‰¤ 1
        gradient: nil
    ),
    MultivariateConstraint<VectorN<Double>>.inequality(
        function: { v in -v[0] },  // x â‰¥ 0
        gradient: nil
    )
    // ... and similarly for all variables
]

// Just use:
let goodSearchRegion = (
    lower: VectorN([0.0, 0.0, 0.0]),
    upper: VectorN([1.0, 1.0, 1.0])
)

// Save constraints for non-box constraints like:
// x + y â‰¤ 1
// xÂ² + yÂ² = 1
// etc.
```

### 6. Benchmark Your Objective Function

```swift
import Foundation

func benchmarkObjective(
    _ objective: @Sendable (VectorN<Double>) -> Double,
    dimensions: Int
) {
    let testPoint = VectorN(Array(repeating: 0.5, count: dimensions))

    let start = Date()
    let iterations = 1000
    for _ in 0..<iterations {
        _ = objective(testPoint)
    }
    let elapsed = Date().timeIntervalSince(start)

    let timePerEval = elapsed / Double(iterations)
    print("Objective evaluation: \(timePerEval * 1000) ms")

    // Estimate total time
    let totalEvals = 10 * 500  // 10 starts Ã— 500 iterations
    let estimatedTime = timePerEval * Double(totalEvals)
    print("Estimated optimization time (10 starts): \(estimatedTime) seconds")
}

// Usage:
benchmarkObjective(myObjective, dimensions: 5)
```

---

## MCP Tool Integration

The Parallel Optimizer is available through the BusinessMath MCP Server with two tools:

### 1. parallel_optimize

Run parallel multi-start optimization:

```json
{
  "name": "parallel_optimize",
  "arguments": {
    "variables": ["x", "y"],
    "searchRegion": {
      "lower": [-5.0, -5.0],
      "upper": [5.0, 5.0]
    },
    "numberOfStarts": 20,
    "algorithm": "Gradient Descent",
    "maxIterations": 500,
    "tolerance": 1e-6
  }
}
```

### 2. parallel_optimization_guide

Get detailed guidance:

```json
{
  "name": "parallel_optimization_guide",
  "arguments": {
    "topic": "tuning_parameters"
  }
}
```

Available topics:
- `getting_started`: Introduction and quick start
- `tuning_parameters`: How to tune number of starts, algorithm, etc.
- `interpreting_results`: Understanding success rate and result distribution
- `best_practices`: Production deployment patterns

---

## Summary

**Parallel Multi-Start Optimization** is your solution when:
- âœ… Problem might have local minima
- âœ… You need confidence in finding the global optimum
- âœ… You have multiple CPU cores available
- âœ… Result quality matters more than speed
- âœ… Problem landscape is unknown or complex

**Key Takeaways:**
1. Start with 10-20 starts, scale up based on success rate
2. Use success rate as your quality metric (target: >70%)
3. Analyze result distribution to understand problem difficulty
4. Match algorithm to problem type (constraints vs unconstrained)
5. Define search region carefully - not too wide, not too narrow
6. True parallelism via TaskGroup scales with CPU cores
7. Trust the best result when success rate is high

**Phase 7 Complete**: You now have comprehensive optimization capabilities:
- âœ… **AdaptiveOptimizer**: Automatic algorithm selection
- âœ… **PerformanceBenchmark**: Algorithm performance profiling
- âœ… **ParallelOptimizer**: Multi-start global optimization

---

**Questions or Issues?**
- Check the MCP guide tools for specific topics
- Review the 16 test cases in `ParallelOptimizerTests.swift` for examples
- See implementation in `ParallelOptimizer.swift` (333 lines, fully documented)

**Happy Optimizing! ğŸš€**
