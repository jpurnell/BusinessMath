# Conjugate Gradient Optimization

Learn how to use the Conjugate Gradient optimizer for efficient gradient-based optimization with conjugate search directions.

## Overview

Conjugate Gradient (CG) is an iterative optimization algorithm that generates a sequence of conjugate search directions to efficiently navigate the optimization landscape. Unlike steepest descent, CG uses information from previous iterations to choose better search directions, leading to faster convergence.

**When to use Conjugate Gradient:**
- Your function is smooth and differentiable
- You want faster convergence than gradient descent
- You don't need the full Hessian approximation of L-BFGS
- Problem has quadratic or near-quadratic characteristics
- Memory is very limited (even more than L-BFGS)

**When to avoid Conjugate Gradient:**
- Function is non-differentiable or has discontinuities
- Gradients are noisy or unreliable
- Problem is highly non-convex with many local minima
- Ill-conditioned problems (consider L-BFGS instead)

## Algorithm Overview

Conjugate Gradient maintains a search direction that is conjugate to previous directions, ensuring efficient exploration of the optimization landscape. The key innovation is the beta parameter, which combines gradient information with the previous search direction.

### Key Features

- **Four beta formulas**: Fletcher-Reeves, Polak-Ribière, Hestenes-Stiefel, Dai-Yuan
- **Automatic restart**: Optional periodic restart for improved convergence
- **Line search**: Backtracking to ensure sufficient decrease
- **Memory efficient**: Only stores current and previous gradient

### Conjugate Gradient Iteration

1. Compute gradient at current position
2. Calculate beta parameter using selected formula
3. Update search direction: d = -g + β·d_prev
4. Perform line search along direction
5. Update position
6. Optionally restart to steepest descent

## Basic Usage

### Simple Quadratic Minimization

The simplest use case is minimizing a quadratic function:

```swift
import BusinessMath

// Define objective function: f(x) = (x - 3)²
let objective: (Double) -> Double = { x in
    (x - 3.0) * (x - 3.0)
}

// Create Conjugate Gradient optimizer
let optimizer = AsyncConjugateGradientOptimizer(
    method: .fletcherReeves,
    tolerance: 1e-6,
    maxIterations: 100
)

// Optimize
let result = try await optimizer.optimize(
    objective: objective,
    constraints: [],
    initialGuess: 0.0,
    bounds: nil
)

print("Optimal value: \(result.optimalValue)")  // ≈ 3.0
print("Objective at optimum: \(result.objectiveValue)")  // ≈ 0.0
print("Converged: \(result.converged)")
print("Iterations: \(result.iterations)")
```

### Choosing a Beta Method

Different beta formulas have different convergence characteristics:

```swift
// Fletcher-Reeves: Classic, robust for quadratic problems
let frOptimizer = AsyncConjugateGradientOptimizer(
    method: .fletcherReeves,
    tolerance: 1e-6,
    maxIterations: 100
)

// Polak-Ribière: Often faster, better for non-quadratic
let prOptimizer = AsyncConjugateGradientOptimizer(
    method: .polakRibiere,
    tolerance: 1e-6,
    maxIterations: 100
)

// Hestenes-Stiefel: Good for difficult problems
let hsOptimizer = AsyncConjugateGradientOptimizer(
    method: .hestenesStiefel,
    tolerance: 1e-6,
    maxIterations: 100
)

// Dai-Yuan: Often most efficient for general problems
let dyOptimizer = AsyncConjugateGradientOptimizer(
    method: .daiYuan,
    tolerance: 1e-6,
    maxIterations: 100
)
```

**Method selection guidelines:**
- **Fletcher-Reeves**: Safe default, best for quadratic problems
- **Polak-Ribière**: Faster convergence, good for non-quadratic functions
- **Hestenes-Stiefel**: Robust for difficult landscapes
- **Dai-Yuan**: Often the best choice for general optimization

## Restart Mechanisms

Periodic restarts to steepest descent can improve convergence on difficult problems:

```swift
// Restart every 20 iterations
let optimizer = AsyncConjugateGradientOptimizer(
    method: .polakRibiere,
    tolerance: 1e-6,
    maxIterations: 200,
    restartInterval: 20  // Restart to steepest descent every 20 iterations
)

let result = try await optimizer.optimize(
    objective: objective,
    constraints: [],
    initialGuess: 5.0,
    bounds: nil
)
```

**Restart interval guidelines:**
- **nil**: No automatic restart (default)
- **10-20**: Aggressive restart for difficult problems
- **50-100**: Conservative restart for smooth problems
- **n (problem dimension)**: Classic rule for n-dimensional problems

## Adaptive Progress Reporting

Conjugate Gradient supports real-time progress monitoring with configurable reporting strategies.

### Fixed Interval Progress

Report progress every N iterations:

```swift
let optimizer = AsyncConjugateGradientOptimizer(
    method: .polakRibiere,
    tolerance: 1e-6,
    maxIterations: 100,
    progressStrategy: FixedIntervalStrategy(interval: 10)
)

let result = try await optimizer.optimizeWithProgress(
    objective: objective,
    constraints: [],
    initialGuess: 0.0,
    bounds: nil
) { progress in
    print("Iteration \(progress.iteration): " +
          "beta = \(progress.beta), " +
          "gradient norm = \(progress.metrics.gradientNorm)")
}
```

### Exponential Backoff Progress

Report frequently at first, then less often:

```swift
let optimizer = AsyncConjugateGradientOptimizer(
    method: .daiYuan,
    tolerance: 1e-6,
    maxIterations: 1000,
    progressStrategy: ExponentialBackoffStrategy(
        initialInterval: 1,
        maxInterval: 100,
        backoffFactor: 2.0
    )
)
```

This strategy reports at iterations: 1, 2, 4, 8, 16, 32, 64, 100, 200, 300...

### Convergence-Based Progress

Report more frequently when convergence is slow:

```swift
let optimizer = AsyncConjugateGradientOptimizer(
    method: .hestenesStiefel,
    tolerance: 1e-6,
    maxIterations: 1000,
    progressStrategy: ConvergenceBasedStrategy(
        minInterval: 5,
        maxInterval: 50,
        convergenceThreshold: 0.01
    )
)
```

## Early Stopping with Convergence Detection

Stop optimization early when progress stagnates:

```swift
let detector = ConvergenceDetector(
    windowSize: 10,
    improvementThreshold: 0.001,
    gradientThreshold: 0.01
)

let optimizer = AsyncConjugateGradientOptimizer(
    method: .polakRibiere,
    tolerance: 1e-10,  // Very tight
    maxIterations: 1000,
    convergenceDetector: detector
)

let result = try await optimizer.optimize(
    objective: objective,
    constraints: [],
    initialGuess: 0.0,
    bounds: nil
)

// Will stop early if improvement < 0.001 for 10 iterations
// or gradient norm < 0.01
```

## AsyncSequence Streaming

Monitor optimization progress in real-time using AsyncSequence:

```swift
let optimizer = AsyncConjugateGradientOptimizer(
    method: .daiYuan,
    tolerance: 1e-6,
    maxIterations: 100,
    progressStrategy: FixedIntervalStrategy(interval: 5)
)

let stream = optimizer.optimizeWithProgressStream(
    objective: objective,
    constraints: [],
    initialGuess: 10.0,
    bounds: nil
)

for try await progress in stream {
    if let result = progress.result {
        // Final result available
        print("Optimization complete!")
        print("Solution: \(result.optimalValue)")
    } else {
        // Intermediate progress
        print("Iteration \(progress.iteration): " +
              "beta = \(progress.beta), " +
              "direction = \(progress.conjugateDirection)")
    }
}
```

## Advanced Examples

### Rosenbrock Function

The Rosenbrock function is a classic challenging test case:

```swift
// f(x) = (1-x)² + 100(2-x²)²  (1D version)
// Global minimum at x = 1
let rosenbrock: (Double) -> Double = { x in
    let term1 = (1.0 - x) * (1.0 - x)
    let term2 = 100.0 * (2.0 - x * x) * (2.0 - x * x)
    return term1 + term2
}

let optimizer = AsyncConjugateGradientOptimizer(
    method: .polakRibiere,  // PR often best for Rosenbrock
    tolerance: 1e-4,
    maxIterations: 200,
    restartInterval: 20  // Periodic restart helps
)

let result = try await optimizer.optimize(
    objective: rosenbrock,
    constraints: [],
    initialGuess: 0.0,
    bounds: nil
)

print("Found minimum at: \(result.optimalValue)")  // ≈ 1.0
```

### Comparing Beta Methods

Test different methods on the same problem:

```swift
let objective: (Double) -> Double = { x in
    (x - 5.0) * (x - 5.0)
}

let methods: [ConjugateGradientMethod] = [
    .fletcherReeves,
    .polakRibiere,
    .hestenesStiefel,
    .daiYuan
]

for method in methods {
    let optimizer = AsyncConjugateGradientOptimizer(
        method: method,
        tolerance: 1e-6,
        maxIterations: 100
    )

    let result = try await optimizer.optimize(
        objective: objective,
        constraints: [],
        initialGuess: 0.0,
        bounds: nil
    )

    print("\(method): \(result.iterations) iterations")
}
```

### High-Precision Optimization

For very tight tolerances:

```swift
let optimizer = AsyncConjugateGradientOptimizer(
    method: .daiYuan,
    tolerance: 1e-12,  // Extremely tight
    maxIterations: 500,
    restartInterval: 50
)

let result = try await optimizer.optimize(
    objective: { x in (x - 7.0) * (x - 7.0) },
    constraints: [],
    initialGuess: 0.0,
    bounds: nil
)

print("High-precision result: \(result.optimalValue)")  // Very close to 7.0
print("Function value: \(result.objectiveValue)")  // ≈ 0.0 within 1e-12
```

## Performance Characteristics

Conjugate Gradient performance depends on several factors:

### Convergence Rate

- **Quadratic functions**: Converges in n iterations for n-dimensional problems
- **Near-quadratic**: Superlinear convergence
- **Highly non-quadratic**: May benefit from restarts

### Method Comparison

| Method | Speed | Robustness | Best For |
|--------|-------|------------|----------|
| Fletcher-Reeves | Medium | High | Quadratic problems |
| Polak-Ribière | Fast | Medium | Non-quadratic functions |
| Hestenes-Stiefel | Medium | High | Difficult landscapes |
| Dai-Yuan | Fast | High | General optimization |

### Iteration Count Examples

```swift
// Simple quadratic: ~5-15 iterations (all methods)
(x - 4)²

// Rosenbrock: ~30-80 iterations
(1-x)² + 100(2-x²)²
// PR and DY typically fastest

// Already optimal: 1-2 iterations
Starting at x = 4 for (x - 4)²
```

### Restart Impact

Restarts can significantly affect convergence:

```swift
// Without restart: May oscillate on difficult problems
// With restart every 20: More stable, slightly slower
// With restart every 50: Good balance for most problems
```

## Troubleshooting

### Slow Convergence

If Conjugate Gradient converges slowly:

1. **Try different beta method**: Polak-Ribière or Dai-Yuan often fastest
2. **Add periodic restart**: Try restartInterval = 20 or 50
3. **Adjust tolerance**: Relax if high precision isn't needed
4. **Check initial guess**: Start closer to the optimum
5. **Consider L-BFGS**: May be faster for difficult problems

### Oscillation or Divergence

If optimization oscillates:

1. **Enable restart**: Try restartInterval = 10
2. **Try Fletcher-Reeves**: More stable than other methods
3. **Check function smoothness**: CG requires differentiable functions
4. **Verify gradients**: Numerical gradient should be accurate

### Premature Convergence

If optimization stops too early:

1. **Tighten tolerance**: Use 1e-8 or smaller
2. **Increase max iterations**: Allow more time
3. **Disable convergence detector**: Remove if too aggressive
4. **Check beta method**: FR may be too conservative

### Method Selection Issues

If unsure which method to use:

1. **Start with Dai-Yuan**: Often best overall performance
2. **Try Polak-Ribière**: If you need speed over robustness
3. **Fall back to Fletcher-Reeves**: If others are unstable
4. **Use Hestenes-Stiefel**: For very difficult problems

## Comparison with Other Optimizers

### vs. Gradient Descent
- **CG**: Much faster convergence, conjugate directions
- **GD**: Simpler, but much slower

### vs. L-BFGS
- **CG**: Less memory, simpler, good for near-quadratic
- **L-BFGS**: Better for general problems, more robust

### vs. Nelder-Mead
- **CG**: Requires gradients, faster convergence
- **NM**: Derivative-free, better for non-smooth functions

### vs. Simulated Annealing
- **CG**: Local optimization, very fast
- **SA**: Global optimization, handles non-convexity

## Next Steps

- Review <doc:5.20-LBFGSOptimizationTutorial> for a more robust quasi-Newton method
- Learn about <doc:5.22-SimulatedAnnealingTutorial> for global optimization
- Try <doc:5.23-NelderMeadTutorial> for derivative-free optimization
- Explore <doc:5.5-MultivariateOptimization> for multivariate problems

## See Also

- ``AsyncConjugateGradientOptimizer``
- ``ConjugateGradientMethod``
- ``ConjugateGradientProgress``
- ``ProgressStrategy``
- ``FixedIntervalStrategy``
- ``ExponentialBackoffStrategy``
- ``ConvergenceBasedStrategy``
- ``ConvergenceDetector``
- ``ConvergenceMetrics``
- ``OptimizationResult``
