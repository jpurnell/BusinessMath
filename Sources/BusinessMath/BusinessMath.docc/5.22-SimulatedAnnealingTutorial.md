# Simulated Annealing Optimization

Learn how to use the Simulated Annealing optimizer for global optimization of complex, multimodal functions.

## Overview

Simulated Annealing (SA) is a probabilistic metaheuristic inspired by the annealing process in metallurgy. Unlike gradient-based methods that can get stuck in local minima, SA can escape them by occasionally accepting worse solutions with decreasing probability as the "temperature" cools.

**When to use Simulated Annealing:**
- Function has many local minima (multimodal)
- Function is non-differentiable or discontinuous
- Global optimum is needed, not just local minimum
- Objective is noisy or stochastic
- Problem dimension is moderate (1-100 variables)

**When to avoid Simulated Annealing:**
- Function is smooth and unimodal (use L-BFGS or CG instead)
- You need very high precision (SA is approximate)
- Very high dimensions (>100 variables)
- Extremely tight time constraints (SA is slower)

## Algorithm Overview

Simulated Annealing gradually "cools" a system to find low-energy (optimal) states. At high temperatures, it freely explores by accepting both better and worse solutions. As temperature decreases, it becomes increasingly selective, eventually settling into a good minimum.

### Key Features

- **Probabilistic acceptance**: Accept worse solutions with probability exp(-ΔE/T)
- **Temperature schedule**: Geometric cooling T_new = α·T_old
- **Global exploration**: Can escape local minima early in search
- **Derivative-free**: Works without gradients
- **Constraint support**: Handles equality/inequality constraints via penalty method
- **Reproducible**: Optional seed for deterministic results

### Simulated Annealing Iteration

1. Generate neighbor by randomly perturbing current solution
2. Evaluate energy change ΔE = E_new - E_current
3. Always accept if ΔE < 0 (better)
4. Accept if ΔE ≥ 0 with probability exp(-ΔE/T) (worse)
5. Cool temperature: T = α·T
6. Optionally reheat to escape stagnation

## Basic Usage

### Simple Sphere Function

Minimize a simple quadratic function in 2D:

```swift
import BusinessMath

// Define objective: f(x,y) = x² + y²
let sphere: (VectorN<Double>) -> Double = { v in
    v.dot(v)
}

// Create optimizer with search space bounds
let optimizer = SimulatedAnnealing<VectorN<Double>>(
    config: .default,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]  // Bounds for each dimension
)

// Optimize
let result = try optimizer.minimize(
    sphere,
    from: VectorN([5.0, 5.0])
)

print("Optimal value: \(result.solution)")  // ≈ [0.0, 0.0]
print("Objective at optimum: \(result.value)")  // ≈ 0.0
print("Converged: \(result.converged)")
print("Iterations: \(result.iterations)")
```

### Configuring Temperature Schedule

Temperature parameters critically affect SA performance:

```swift
// Fast cooling (quick but less thorough)
let fastOptimizer = SimulatedAnnealing<VectorN<Double>>(
    config: .fast,  // T₀=50, α=0.85, 500 iterations
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Slow cooling (thorough but slower)
let thoroughOptimizer = SimulatedAnnealing<VectorN<Double>>(
    config: .thorough,  // T₀=200, α=0.98, 5000 iterations
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Custom cooling schedule
let customOptimizer = SimulatedAnnealing<VectorN<Double>>(
    config: SimulatedAnnealingConfig(
        initialTemperature: 100.0,  // High initial exploration
        finalTemperature: 0.001,     // Low final exploitation
        coolingRate: 0.95,           // Moderate cooling
        maxIterations: 2000,
        perturbationScale: 0.3       // Neighbor generation scale
    ),
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)
```

**Temperature guidelines:**
- **High T₀ (100-200)**: More global exploration, finds better minima
- **Low T₀ (10-50)**: Faster convergence, may miss global optimum
- **Slow cooling (α=0.95-0.99)**: Better quality, more iterations
- **Fast cooling (α=0.80-0.90)**: Faster but less reliable

## Multimodal Optimization

SA excels at multimodal functions where gradient methods fail:

### Rastrigin Function

A classic multimodal test function with many local minima:

```swift
// Rastrigin: f(x,y) = 20 + x² + y² - 10(cos(2πx) + cos(2πy))
// Many local minima, global minimum at (0, 0)
let rastrigin: (VectorN<Double>) -> Double = { v in
    let x = v[0], y = v[1]
    let A = 10.0
    let n = 2.0
    return A * n + (x * x - A * cos(2.0 * .pi * x)) +
                   (y * y - A * cos(2.0 * .pi * y))
}

let optimizer = SimulatedAnnealing<VectorN<Double>>(
    config: .thorough,  // Needs slow cooling for this difficult function
    searchSpace: [(-5.12, 5.12), (-5.12, 5.12)]
)

let result = try optimizer.minimize(
    rastrigin,
    from: VectorN([4.0, 4.0])  // Start far from optimum
)

print("Found minimum at: \(result.solution)")  // ≈ [0.0, 0.0]
print("Objective value: \(result.value)")  // ≈ 0.0
```

### Ackley Function

Another challenging multimodal benchmark:

```swift
// Ackley function: many local minima, global at (0, 0)
let ackley: (VectorN<Double>) -> Double = { v in
    let x = v[0], y = v[1]
    let a = 20.0
    let b = 0.2
    let c = 2.0 * .pi

    let sum1 = x * x + y * y
    let sum2 = cos(c * x) + cos(c * y)

    return -a * exp(-b * sqrt(sum1 / 2.0)) - exp(sum2 / 2.0) + a + exp(1.0)
}

let optimizer = SimulatedAnnealing<VectorN<Double>>(
    config: SimulatedAnnealingConfig(
        initialTemperature: 150.0,
        coolingRate: 0.97,
        maxIterations: 3000,
        perturbationScale: 0.25
    ),
    searchSpace: [(-5.0, 5.0), (-5.0, 5.0)]
)

let result = try optimizer.minimize(ackley, from: VectorN([3.0, -3.0]))
```

## Reheating for Escape

Periodic temperature increases help escape local minima:

```swift
// Configuration with reheating every 200 iterations
let config = SimulatedAnnealingConfig(
    initialTemperature: 100.0,
    finalTemperature: 0.001,
    coolingRate: 0.95,
    maxIterations: 2000,
    perturbationScale: 0.3,
    reheatInterval: 200,        // Reheat every 200 iterations
    reheatTemperature: 50.0     // Boost back to 50.0
)

let optimizer = SimulatedAnnealing<VectorN<Double>>(
    config: config,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Reheating allows multiple exploration phases
let result = try optimizer.minimize(difficultFunction, from: initialGuess)
```

**Reheating guidelines:**
- **None**: For smooth, well-behaved functions
- **Every 100-300 iterations**: For highly multimodal problems
- **Reheat to T₀/2**: Conservative restart
- **Reheat to T₀**: Aggressive re-exploration

## Perturbation Scale

Controls the size of random jumps when generating neighbors:

```swift
// Small perturbations (fine-grained search)
let fineOptimizer = SimulatedAnnealing<VectorN<Double>>(
    config: SimulatedAnnealingConfig(
        perturbationScale: 0.1  // Small jumps
    ),
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

// Large perturbations (broad exploration)
let broadOptimizer = SimulatedAnnealing<VectorN<Double>>(
    config: SimulatedAnnealingConfig(
        perturbationScale: 0.7  // Large jumps
    ),
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)
```

**Perturbation scale guidelines:**
- **0.1-0.2**: Fine-grained local search
- **0.3-0.4**: Balanced exploration/exploitation (default: 0.3)
- **0.5-0.7**: Broad global exploration
- **>0.7**: Very aggressive, may be too random

## Reproducible Results

Use a seed for deterministic optimization:

```swift
import BusinessMath

let objective: (VectorN<Double>) -> Double = { v in
    v.dot(v)  // Minimize sphere function
}

let initialGuess = VectorN([5.0, 5.0])

// Create optimizer with fixed seed
let config1 = SimulatedAnnealingConfig(
    seed: 12345  // Fixed seed for reproducibility
)

let optimizer1 = SimulatedAnnealing<VectorN<Double>>(
    config: config1,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

let result1 = try optimizer1.minimize(objective, from: initialGuess)

// Create NEW optimizer with SAME seed for reproducible result
let config2 = SimulatedAnnealingConfig(
    seed: 12345  // Same seed as above
)

let optimizer2 = SimulatedAnnealing<VectorN<Double>>(
    config: config2,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

let result2 = try optimizer2.minimize(objective, from: initialGuess)

// Results are identical when using same seed
print("Result 1: \(result1.solution.toArray())")
print("Result 2: \(result2.solution.toArray())")
print("Results match: \(result1.solution.toArray() == result2.solution.toArray())")
```

**Expected Output:**
```
Result 1: [-0.023, 0.041]
Result 2: [-0.023, 0.041]
Results match: true
```

**★ Insight ─────────────────────────────────────**
Why create separate optimizer instances?

The seed controls the random number generator's **initial state**, not its behavior across multiple runs. When you call `minimize()`, the RNG state advances with each random decision (temperature updates, neighbor generation, acceptance tests).

**Wrong approach (doesn't work):**
```swift
let optimizer = SimulatedAnnealing(config: SimulatedAnnealingConfig(seed: 42), ...)
let result1 = try optimizer.minimize(...)  // RNG state: [42, 193, 847, ...]
let result2 = try optimizer.minimize(...)  // RNG state: [472, 918, 234, ...] ❌ Different!
```

**Correct approach:**
```swift
let opt1 = SimulatedAnnealing(config: SimulatedAnnealingConfig(seed: 42), ...)
let result1 = try opt1.minimize(...)  // RNG state: [42, 193, 847, ...]

let opt2 = SimulatedAnnealing(config: SimulatedAnnealingConfig(seed: 42), ...)
let result2 = try opt2.minimize(...)  // RNG state: [42, 193, 847, ...] ✅ Same!
```
```
This is like shuffling a deck - using the same shuffle algorithm (seed) produces the same order, but you need a fresh deck each time, not one that's already been shuffled!
**─────────────────────────────────────────────────**
```

## Detailed Results

Access detailed optimization information:

```swift
let optimizer = SimulatedAnnealing<VectorN<Double>>(
    config: .default,
    searchSpace: [(-10.0, 10.0), (-10.0, 10.0)]
)

let result = optimizer.optimizeDetailed(
    objective: rosenbrock,
    initialSolution: VectorN([0.0, 0.0])
)

print("Solution: \(result.solution)")
print("Fitness: \(result.fitness)")
print("Iterations: \(result.iterations)")
print("Evaluations: \(result.evaluations)")
print("Final temperature: \(result.finalTemperature)")
print("Acceptance rate: \(result.acceptanceRate)")  // Accepted / total
print("Converged: \(result.converged)")
print("Reason: \(result.convergenceReason)")

// Access convergence history
if let history = result.convergenceHistory {
    print("Best value over time: \(history)")
}
```

## Constrained Optimization

SA handles constraints via penalty method:

```swift
// Minimize x² + y² subject to x + y = 2
let objective: (VectorN<Double>) -> Double = { v in
    v.dot(v)
}

let constraint: MultivariateConstraint<VectorN<Double>> = .equality(
    function: { v in v[0] + v[1] - 2.0 },
    gradient: { _ in VectorN([1.0, 1.0]) }
)

let optimizer = SimulatedAnnealing<VectorN<Double>>(
    config: .default,
    searchSpace: [(-5.0, 5.0), (-5.0, 5.0)]
)

let result = try optimizer.minimize(
    objective,
    from: VectorN([3.0, 3.0]),
    constraints: [constraint]
)

// Solution approximately (1, 1) satisfying x + y = 2
print("Solution: \(result.solution)")
let constraintValue = result.solution[0] + result.solution[1]
print("Constraint value: \(constraintValue)")  // ≈ 2.0
```

## High-Dimensional Problems

SA scales to moderate dimensions:

```swift
// 10-dimensional sphere function
let objective: (VectorN<Double>) -> Double = { v in
    v.dot(v)
}

// Define 10D search space
let searchSpace = Array(repeating: (-10.0, 10.0), count: 10)

let optimizer = SimulatedAnnealing<VectorN<Double>>(
    config: SimulatedAnnealingConfig(
        initialTemperature: 200.0,  // Higher for more dimensions
        coolingRate: 0.98,           // Slower for more dimensions
        maxIterations: 5000,         // More iterations for more dimensions
        perturbationScale: 0.2       // Smaller for more dimensions
    ),
    searchSpace: searchSpace
)

let initialGuess = VectorN(Array(repeating: 5.0, count: 10))
let result = try optimizer.minimize(objective, from: initialGuess)
```

**Dimensional scaling guidelines:**
- **1-5D**: Default config works well
- **5-20D**: Increase iterations 2-3x, slower cooling
- **20-50D**: Increase T₀, much slower cooling (0.98-0.99)
- **50-100D**: Consider hybrid approaches or specialized methods
- **>100D**: SA becomes impractical

## Performance Characteristics

SA performance depends on several factors:

### Convergence Rate

- **Smooth unimodal**: ~100-500 iterations (but gradient methods better)
- **Multimodal with few minima**: ~500-2000 iterations
- **Highly multimodal**: ~2000-10000 iterations
- **High-dimensional**: Scales exponentially

### Acceptance Rate Diagnostics

The acceptance rate reveals search behavior:

```swift
let result = optimizer.optimizeDetailed(objective: f, initialSolution: x0)
let acceptanceRate = result.acceptanceRate

if acceptanceRate < 0.1 {
    print("Warning: Very low acceptance, cooling too fast or T₀ too low")
} else if acceptanceRate > 0.9 {
    print("Warning: Very high acceptance, cooling too slow or T₀ too high")
} else {
    print("Good acceptance rate: \(acceptanceRate)")
}
```

**Acceptance rate guidelines:**
- **<10%**: Cooling too fast, not exploring enough
- **10-40%**: Good balance (typical for default config)
- **40-70%**: High exploration, may be inefficient
- **>70%**: Almost random walk, cooling too slow

### Quality vs Speed Trade-off

| Configuration | Speed | Quality | Best For |
|---------------|-------|---------|----------|
| .fast | Fast (500 iter) | Good | Preliminary search |
| .default | Medium (1000 iter) | Better | General use |
| .thorough | Slow (5000 iter) | Best | Final optimization |

## Troubleshooting

### Poor Solutions

If SA finds poor local minima:

1. **Increase initial temperature**: Try T₀ = 150 or 200
2. **Slow down cooling**: Use α = 0.97 or 0.98
3. **Enable reheating**: Add reheatInterval and reheatTemperature
4. **Increase iterations**: Allow more time to explore
5. **Adjust perturbation scale**: Try 0.4-0.5 for broader search

### Very Slow Convergence

If SA takes too long:

1. **Reduce iterations**: Lower maxIterations
2. **Faster cooling**: Use α = 0.85-0.90
3. **Lower initial temperature**: Try T₀ = 50
4. **Consider gradient methods**: If function is smooth, use L-BFGS or CG

### Erratic Behavior

If optimization is unstable:

1. **Set a seed**: Use `seed` parameter for reproducibility
2. **Adjust perturbation scale**: Reduce to 0.2-0.3
3. **Check search space bounds**: Ensure reasonable ranges
4. **Verify objective function**: Check for NaN or Inf values

### High Acceptance Rate

If almost all moves accepted:

1. **Lower initial temperature**: Reduce T₀
2. **Faster cooling**: Decrease α
3. **Check objective scale**: Very flat objectives need different tuning

## Comparison with Other Optimizers

### vs. L-BFGS / Conjugate Gradient
- **SA**: Global search, derivative-free, handles non-smooth functions
- **L-BFGS/CG**: Local search, fast convergence, requires smoothness

### vs. Nelder-Mead
- **SA**: Probabilistic, can escape local minima, better for multimodal
- **NM**: Deterministic simplex, faster for unimodal functions

### vs. Genetic Algorithms
- **SA**: Single-solution trajectory, simpler, faster for small populations
- **GA**: Population-based, better for very difficult landscapes

### vs. Particle Swarm
- **SA**: Temperature-based acceptance, single particle
- **PSO**: Swarm intelligence, multiple particles, faster parallelization

## When to Choose Simulated Annealing

Choose SA when:
- Function has many local minima (multimodal landscape)
- Gradients unavailable or unreliable
- Function is discontinuous or non-smooth
- Global optimum needed (not just local minimum)
- Willing to trade speed for solution quality

Avoid SA when:
- Function is smooth and unimodal (use L-BFGS or CG)
- Very high precision needed (SA is approximate)
- Very high dimensions (>100 variables)
- Computational budget is very tight

## Next Steps

- Review <doc:5.20-LBFGSOptimizationTutorial> for fast gradient-based optimization
- Try <doc:5.21-ConjugateGradientTutorial> for another gradient method
- Explore <doc:5.23-NelderMeadTutorial> for deterministic derivative-free optimization
- Learn about <doc:5.5-MultivariateOptimization> for multivariate theory

## See Also

- ``SimulatedAnnealing``
- ``SimulatedAnnealingConfig``
- ``SimulatedAnnealingResult``
- ``MultivariateOptimizer``
- ``MultivariateConstraint``
- ``MultivariateOptimizationResult``
- ``VectorSpace``
- ``VectorN``
