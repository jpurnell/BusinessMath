# Multivariate Optimization

Solving real-world problems like portfolio optimization, cost minimization, and parameter fitting.

---

## Table of Contents

1. [Overview](#overview)
2. [Numerical Differentiation](#numerical-differentiation)
3. [Gradient Descent Optimizers](#gradient-descent-optimizers)
4. [Newton-Raphson Optimizers](#newton-raphson-optimizers)
5. [Portfolio Optimization](#portfolio-optimization)
6. [Integration Examples](#integration-examples)
7. [Best Practices](#best-practices)

---

## Overview

This tutorial explains the techniques that extend BusinessMath from scalar optimization (single variable) to **multivariate optimization** (multiple variables). This enables solving real-world problems like portfolio optimization, cost minimization, and parameter fitting.

### What's Included

- **Numerical Differentiation**: Automatic gradient and Hessian computation
- **Gradient Descent**: Basic, Momentum, and Nesterov acceleration variants
- **Newton-Raphson**: Full Newton and BFGS quasi-Newton methods
- **Adaptive Optimizer**: Automatic algorithm selection based on problem characteristics
- **Portfolio Optimization**: Minimum variance, maximum Sharpe, efficient frontier

### Design Philosophy

All optimizers work with the `VectorSpace` protocol, making them generic and reusable:
- Works with `VectorN<Double>` (N-dimensional vectors)
- Works with `Vector2D`, `Vector3D` for specific dimensions
- Extensible to custom vector types

---

## Numerical Differentiation

### What Problems Does It Solve?

When you have a complex function but can't compute derivatives analytically, numerical differentiation automatically computes:
- **Gradients** (first derivatives) - direction of steepest ascent
- **Hessians** (second derivatives) - curvature information
- **Jacobians** (for systems of equations)

### Quick Start

```swift
import BusinessMath

// Define a function: f(x,y) = x² + 2y²
let function: (VectorN<Double>) -> Double = { v in
    let x = v[0]
    let y = v[1]
    return x*x + 2*y*y
}

// Compute gradient at point (1, 2)
let point = VectorN([1.0, 2.0])
let gradient = try numericalGradient(function, at: point)
// gradient ≈ [2.0, 8.0]  (∂f/∂x = 2x, ∂f/∂y = 4y)

// Compute Hessian (curvature)
let hessian = try numericalHessian(function, at: point)
// hessian ≈ [[2, 0], [0, 4]]  (∂²f/∂x² = 2, ∂²f/∂y² = 4)
```

### API Reference

#### `numericalGradient<V: VectorSpace>`
Computes the gradient (first derivatives) using central finite differences.

```swift
func numericalGradient<V: VectorSpace>(
    function: @escaping (V) -> Double,
    at point: V,
    epsilon: Double = 1e-5
) -> V
```

**Parameters:**
- `function`: Function to differentiate
- `point`: Point at which to compute gradient
- `epsilon`: Finite difference step (default: 1e-5)

**Returns:** Gradient vector (same type as `point`)

**Example:**
```swift
// Rosenbrock function: f(x,y) = (1-x)² + 100(y-x²)²
let rosenbrock: (VectorN<Double>) -> Double = { v in
    let x = v[0], y = v[1]
    let a = 1 - x
    let b = y - x*x
    return a*a + 100*b*b
}

let grad = try numericalGradient(rosenbrock, at: VectorN([0.0, 0.0]))
print(grad.map({ $0.rounded() }))  // Shows direction to minimum
```

#### `numericalHessian<V: VectorSpace>`
Computes the Hessian (second derivatives) for curvature information.

```swift
func numericalHessian<V: VectorSpace>(
    of function: @escaping (V) -> Double,
    at point: V,
    stepSize: Double = 1e-4
) -> [[Double]]
```

**Returns:** N×N matrix of second derivatives

**Use Cases:**
- Newton-Raphson optimization (requires Hessian)
- Identifying saddle points vs. minima
- Sensitivity analysis

---

## Gradient Descent Optimizers

### What Problems Does It Solve?

Gradient descent finds the minimum of a function by iteratively moving in the direction of steepest descent. The `GradientDescentOptimizer` supports:

1. **Basic Gradient Descent**: Simple, reliable (momentum = 0.0)
2. **Momentum**: Faster convergence, less oscillation (default: momentum ≈ 0.8)
3. **Nesterov Acceleration**: Look-ahead gradient for even faster convergence (useNesterov = true)

Note: For automatic algorithm selection based on problem characteristics, use `AdaptiveOptimizer`.

### Quick Start

```swift
import BusinessMath

// Find minimum of f(x,y) = x² + 2y²
let function: (VectorN<Double>) -> Double = { v in
    v[0]*v[0] + 4*v[1]*v[1]
}

// Basic gradient descent
var gradientDescentOptimizer = MultivariateGradientDescent<VectorN<Double>>(learningRate: 0.01)
	let gradientDescentResult = try gradientDescentOptimizer.minimize(
		function: function,
		gradient: { x in try numericalGradient(function, at: x) },
		initialGuess: VectorN([5.0, 5.0])  // Starting point
	)

print("Minimum at: \(gradientDescentResult.solution.toArray().map({ $0.rounded() }))")  // ≈ [0, 0]
print("Value: \(gradientDescentResult.objectiveValue.rounded())")          // ≈ 0
print("Converged: \(gradientDescentResult.converged)")  // true```

### API Reference

#### Basic Gradient Descent

```swift
struct MultivariateGradientDescent<V: VectorSpace> {
    init(
        learningRate: Double = 0.01,
        maxIterations: Int = 1000,
        tolerance: Double = 1e-6
    )

    func minimize(
        _ function: @escaping (V) -> Double,
        from initialGuess: V
    ) throws -> OptimizationResult<V>
}
```

**Parameters:**
- `learningRate`: Step size (default: 0.01). Larger = faster but less stable
- `maxIterations`: Maximum iterations before giving up
- `tolerance`: Convergence threshold (gradient magnitude)

**Example:**
```swift
// Minimize sum of squares: f(x₁,...,xₙ) = Σxᵢ²
let sumOfSquares: (VectorN<Double>) -> Double = { v in
	v.map { $0 * $0 }.reduce(0, +)
}

gradientDescentOptimizer = MultivariateGradientDescent<VectorN<Double>>(
	learningRate: 0.1,
	maxIterations: 500
)

let sumOfSquaresResult = try gradientDescentOptimizer.minimize(
	function: sumOfSquares,
	gradient: { x in try numericalGradient(sumOfSquares, at: x) },
	initialGuess: VectorN([10.0, 20.0, 30.0])
)
print(sumOfSquaresResult.solution.map({ $0.rounded() }))
// Result: ≈ [0.0, 0.0, 0.0]
```

#### Gradient Descent with Momentum

Momentum is built into `GradientDescentOptimizer` and accelerates convergence while reducing oscillation.

```swift
struct GradientDescentOptimizer<T: Real> {
    init(
        learningRate: T = 0.01,
        tolerance: T = 0.0001,
        maxIterations: Int = 1000,
        momentum: T = 0.9,         // Momentum coefficient
        useNesterov: Bool = false  // Use Nesterov acceleration
    )
}
```

**Momentum parameter:**
- `0.0`: No momentum (equivalent to basic gradient descent)
- `0.797...`: Default value (good balance)
- `0.9`: Standard momentum (recommended for most problems)
- `0.99`: High momentum (for very smooth landscapes)

**Nesterov Acceleration:**
- `false`: Standard momentum (default)
- `true`: Nesterov Accelerated Gradient (often faster convergence)

**Example:**
```swift
// Deep valley - momentum helps
let deepValley: (Double) -> Double = { x in
    return x*x
}

// Standard momentum
let standardMomentumOptimizer = GradientDescentOptimizer<Double>(
	learningRate: 0.1,
	momentum: 0.9,
	useNesterov: false
)

let standardMomentumResult = standardMomentumOptimizer.optimize(
	objective: deepValley,
	constraints: [],
	initialGuess: 10.0,
	bounds: nil
)
// Converges much faster than basic gradient descent
print("Minimum at: \(standardMomentumResult.optimalValue.rounded() )")
print("Value: \(standardMomentumResult.objectiveValue.number(1))")
print("Converged: \(standardMomentumResult.converged)")
print("Iterations: \(standardMomentumResult.iterations)")

// Nesterov variant (even faster)
let nesterovOptimizer = GradientDescentOptimizer<Double>(
	learningRate: 0.1,
	momentum: 0.9,
	useNesterov: true  // Look-ahead gradient
)

let nesterovResult = nesterovOptimizer.optimize(
	objective: deepValley,
	constraints: [],
	initialGuess: 10.0,
	bounds: nil
)
// Often converges in fewer iterations than standard momentum
print("Minimum at: \(nesterovResult.optimalValue.rounded() )")
print("Value: \(nesterovResult.objectiveValue.number(1))")
print("Converged: \(nesterovResult.converged)")
print("Iterations: \(nesterovResult.iterations)")
```

#### Adaptive Optimizer

Automatically selects the best optimization algorithm based on problem characteristics.

```swift
struct AdaptiveOptimizer<V: VectorSpace> {
    init(
        preferSpeed: Bool = false,
        preferAccuracy: Bool = false,
        maxIterations: Int = 1000,
        tolerance: Double = 1e-6
    )
}
```

**When to use AdaptiveOptimizer:**
- You're unsure which algorithm is best for your problem
- Problem characteristics vary (sometimes constrained, sometimes not)
- You want optimal algorithm selection without manual tuning

**How it works:**
- Analyzes pr
oblem size, constraints, and gradient availability
- Automatically selects: Gradient Descent, Newton-Raphson, Constrained, or Inequality optimizer
- Returns which algorithm was chosen and why

**Example:**
```swift
let rosenbrock: (VectorN<Double>) -> Double = { v in
    let x = v[0], y = v[1]
    return (1-x)*(1-x) + 100*(y-x*x)*(y-x*x)
}

// Let the optimizer decide the best algorithm
let adaptiveOptimizer = AdaptiveOptimizer<VectorN<Double>>()

let adaptiveResult = try adaptiveOptimizer.optimize(
	objective: rosenbrock,
	initialGuess: VectorN([0.0, 0.0]),
	constraints: []
)

print("Solution: \(adaptiveResult.solution.toArray().map({ $0.rounded() }))")
print("Algorithm used: \(adaptiveResult.algorithmUsed)")
print("Reason: \(adaptiveResult.selectionReason)")
// Small problem (2 variables) - using Newton-Raphson for fast convergence
```

### Choosing the Right Optimizer Configuration

| Configuration                      | Speed     | Stability | Best For                                                       |
|------------------------------------|-----------|-----------|----------------------------------------------------------------|
| GradientDescent (momentum=0.0)     | Slow      | High      | Simple, convex problems                                        |
| GradientDescent (momentum=0.9)     | Fast      | Medium    | Smooth landscapes, valleys                                     |
| GradientDescent (useNesterov=true) | Very Fast | Medium    | Convex problems, faster convergence                            |
| AdaptiveOptimizer                  | Varies    | Varies    | Automatic algorithm selection, unknown problem characteristics |

---

## Newton-Raphson Optimizers

### What Problems Does It Solve?

Newton-Raphson methods use second-order information (curvature) to find minima faster than gradient descent. Two variants:

1. **Full Newton**: Uses exact Hessian (fast but expensive)
2. **BFGS**: Quasi-Newton approximation (fast and cheap)

### Quick Start

```swift
import BusinessMath

// Find minimum of quadratic function
let quadratic: (VectorN<Double>) -> Double = { v in
    let x = v[0], y = v[1]
    return x*x + 4*y*y + 2*x*y
}

// BFGS (recommended for most problems)
let bfgsOptimizer = MultivariateNewtonRaphson<VectorN<Double>>()

let bfgsResult = try bfgsOptimizer.minimizeBFGS(
	function: quadratic,
	gradient: { try numericalGradient(quadratic, at: $0) },
	initialGuess: VectorN([10.0, 10.0])
)

print("Found minimum at: \(bfgsResult.solution.toArray().map({ $0.rounded() }))")
print("Converged in \(bfgsResult.iterations) iterations")
```

### API Reference

#### Newton-Raphson Optimizer

```swift
struct MultivariateNewtonRaphson<V: VectorSpace> {
    init(
        maxIterations: Int = 100,
        tolerance: V.Scalar? = nil,
        useLineSearch: Bool = true,
        recordHistory: Bool = false
    )

    // Full Newton-Raphson (uses exact Hessian)
    func minimize(
        function: (V) -> V.Scalar,
        gradient: (V) throws -> V,
        hessian: (V) throws -> [[V.Scalar]],
        initialGuess: V
    ) throws -> MultivariateOptimizationResult<V>

    // BFGS Quasi-Newton (approximates Hessian)
    func minimizeBFGS(
        function: (V) -> V.Scalar,
        gradient: (V) throws -> V,
        initialGuess: V
    ) throws -> MultivariateOptimizationResult<V>
}
```

#### Full Newton Method

Uses exact Hessian for quadratic convergence (very fast near minimum).

**Pros:**
- Quadratic convergence (iterations required ~log log(accuracy))
- Optimal for smooth, well-behaved functions

**Cons:**
- Expensive Hessian computation (O(n²) evaluations)
- Requires positive definite Hessian

**Example:**
```swift
// Convex quadratic - perfect for Newton
let convexQuadratic: (VectorN<Double>) -> Double = { v in
    let x = v[0], y = v[1], z = v[2]
    return 2*x*x + 3*y*y + 4*z*z + x*y
}

let fullNewtonOptimizer = MultivariateNewtonRaphson<VectorN<Double>>()

let fullNewtonResult = try fullNewtonOptimizer.minimize(
    function: convexQuadratic,
    gradient: { try numericalGradient(convexQuadratic, at: $0) },
    hessian: { try numericalHessian(convexQuadratic, at: $0) },
    initialGuess: VectorN([5.0, 5.0, 5.0])
)

print("Found minimum at: \(fullNewtonResult.solution.toArray().map({ $0.rounded() }))")
print("Converged in \(fullNewtonResult.iterations) iterations")
// Typically converges in 1-3 iterations!
```

#### BFGS Method

Builds Hessian approximation iteratively using gradient information only.

**Pros:**
- No Hessian computation required
- Superlinear convergence
- Handles non-positive definite Hessians

**Cons:**
- Slower than full Newton (but still fast)
- Memory: stores N×N matrix

**Example:**
```swift
// Non-convex function - BFGS handles well
let rosenbrock: (VectorN<Double>) -> Double = { v in
    let x = v[0], y = v[1]
    return (1 - x) * (1 - x) + 100 * (y - x*x) * (y - x*x)
}

let bfgsOptimizer = MultivariateNewtonRaphson<VectorN<Double>>(
    maxIterations: 500
)

let result = try bfgsOptimizer.minimizeBFGS(
    function: rosenbrock,
    gradient: { try numericalGradient(rosenbrock, at: $0) },
    initialGuess: VectorN([2.0, 2.0])
)
// BFGS adapts to the landscape
```

### Comparison: Gradient Descent vs. Newton-Raphson

| Feature            | Gradient Descent      | Newton-Raphson                          |
|--------------------|-----------------------|-----------------------------------------|
| Convergence        | Linear                | Quadratic (Newton) / Superlinear (BFGS) |
| Iterations         | 100s-1000s            | 10s-100s                                |
| Cost per iteration | Cheap (gradient only) | Expensive (Hessian) or Medium (BFGS)    |
| Memory             | O(n)                  | O(n²)                                   |
| Best for           | Large-scale, simple   | Small-scale, complex                    |

**Rule of thumb:**
- **< 20 variables**: Use Newton-Raphson (BFGS)
- **> 100 variables**: Use Gradient Descent (with momentum)
- **20-100 variables**: Try both!
- **Unsure?**: Use AdaptiveOptimizer for automatic selection

---

## Portfolio Optimization

### What Problems Does It Solve?

Given:
- N assets with expected returns
- Covariance matrix (risk relationships)
- Optional constraints (no short-selling, position limits)

Find optimal portfolio weights to:
- Minimize risk (variance)
- Maximize Sharpe ratio (risk-adjusted return)
- Balance risk contributions (risk parity)

### Quick Start

```swift
import BusinessMath

// Define 3-asset portfolio
let returns = VectorN([0.10, 0.12, 0.15])  // 10%, 12%, 15% expected returns
let covariance = [
    [0.04, 0.01, 0.02],
    [0.01, 0.09, 0.03],
    [0.02, 0.03, 0.16]
]

let optimizer = PortfolioOptimizer()

// Minimum variance portfolio
let minVar = try optimizer.minimumVariancePortfolio(
	expectedReturns: returns,
	covariance: covariance
)
print("Weights: \(minVar.weights.toArray().map({ $0.number(4)} ))")
print("Risk: \(minVar.volatility.percent(2))")
print("Return: \(minVar.expectedReturn.percent(2))")

// Maximum Sharpe ratio (risk-free rate = 2%)
let maxSharpe = try optimizer.maximumSharpePortfolio(
	expectedReturns: returns,
	covariance: covariance,
	riskFreeRate: 0.02
)
print("Optimal weights: \(maxSharpe.weights.toArray().map({ $0.number(4)}))")
print("Sharpe ratio: \(maxSharpe.sharpeRatio.number(4))")
```

### API Reference

#### PortfolioOptimizer

```swift
struct PortfolioOptimizer {
    init()

    // Minimum variance portfolio
    func minimumVariancePortfolio(
        expectedReturns: VectorN<Double>,
        covariance: [[Double]],
        allowShortSelling: Bool = false
    ) throws -> OptimalPortfolio

    // Maximum Sharpe ratio
    func maximumSharpePortfolio(
        expectedReturns: VectorN<Double>,
        covariance: [[Double]],
        riskFreeRate: Double = 0.02,
        constraintSet: PortfolioConstraintSet = .longOnly
    ) throws -> OptimalPortfolio

    // Risk parity (equal risk contribution)
    func riskParityPortfolio(
        expectedReturns: VectorN<Double>,
        covariance: [[Double]],
        constraintSet: PortfolioConstraintSet = .longOnly
    ) throws -> OptimalPortfolio

    // Efficient frontier
    func efficientFrontier(
        expectedReturns: VectorN<Double>,
        covariance: [[Double]],
        numberOfPoints: Int = 20,
        constraintSet: PortfolioConstraintSet = .longOnly
    ) throws -> EfficientFrontier
}
```

#### OptimalPortfolio Result

```swift
struct OptimalPortfolio {
    let weights: VectorN<Double>       // Portfolio weights
    let expectedReturn: Double          // Expected portfolio return
    let volatility: Double             // Portfolio standard deviation
    let sharpeRatio: Double            // (return - rf) / volatility
    let converged: Bool                // Whether optimization converged
    let iterations: Int                // Number of iterations used
}
```

#### Portfolio Constraints

```swift
enum PortfolioConstraintSet {
    case unconstrained                                    // No constraints except budget
    case longOnly                                        // No short-selling (w ≥ 0)
    case longShort(maxLeverage: Double)                  // Allow shorts with leverage limit
    case boxConstrained(min: Double, max: Double)        // Position limits
    case custom([MultivariateConstraint<VectorN<Double>>])  // Custom constraints
}
```

### Detailed Examples

#### 1. Minimum Variance Portfolio

Find the portfolio with lowest risk.

```swift
let returns = VectorN([0.08, 0.10, 0.12, 0.15])
let covariance = [
    [0.04, 0.01, 0.00, 0.02],
    [0.01, 0.09, 0.02, 0.03],
    [0.00, 0.02, 0.16, 0.04],
    [0.02, 0.03, 0.04, 0.25]
]

let optimizer = PortfolioOptimizer()

// Long-only minimum variance
let minVarResult = try optimizer.minimumVariancePortfolio(
	expectedReturns: exampleReturns,
	covariance: exampleCovariance,
	allowShortSelling: false  // Long-only
)

print("\n\nMinimum Variance Portfolio:")
for (i, weight) in minVarResult.weights.toArray().enumerated() {
	if weight > 0.01 {
		print("\("Asset \(i+1):".paddingLeft(toLength: 10)) \(weight.percent())")
	}
}
print("Sharpe Ratio: \(minVarResult.sharpeRatio.number(2))")
print("Expected Return: \(minVarResult.expectedReturn.percent())")
print("Risk (Std Dev): \(minVarResult.volatility.percent())")
```

#### 2. Maximum Sharpe Ratio

Find the portfolio with best risk-adjusted returns.

```swift
let returns = VectorN([0.08, 0.10, 0.12, 0.15])
let covariance = [
    [0.04, 0.01, 0.00, 0.02],
    [0.01, 0.09, 0.02, 0.03],
    [0.00, 0.02, 0.16, 0.04],
    [0.02, 0.03, 0.04, 0.25]
]

let optimizer = PortfolioOptimizer()

// Risk-free rate = 2%
let resultMS = try optimizer.maximumSharpePortfolio(
	expectedReturns: exampleReturns,
	covariance: exampleCovariance,
	riskFreeRate: 0.02,
	constraintSet: .longOnly
)

print("\n\nMaximum Sharpe Portfolio:")
print()
print("Weights:")
for (i, weight) in resultMS.weights.toArray().enumerated() {
	print("\("Asset \(i+1):".paddingLeft(toLength: 10)) \(weight.percent())")
}
print("Sharpe Ratio: \(resultMS.sharpeRatio.number(2))")
print("Expected Return: \(resultMS.expectedReturn.percent())")
print("Risk (Std Dev): \(resultMS.volatility.percent())")
```

#### 3. Efficient Frontier

Generate the risk-return trade-off curve.

```swift
let returns = VectorN([0.08, 0.10, 0.12, 0.15])
let covariance = [
    [0.04, 0.01, 0.00, 0.02],
    [0.01, 0.09, 0.02, 0.03],
    [0.00, 0.02, 0.16, 0.04],
    [0.02, 0.03, 0.04, 0.25]
]

let optimizer = PortfolioOptimizer()
let frontier = try optimizer.efficientFrontier(
	expectedReturns: returns,
	covariance: covariance,
	numberOfPoints: 25
)

print("\n\nEfficient Frontier (\(frontier.portfolios.count) points):")
print("   Risk  | Return  |  Sharpe")
print("---------|---------|----------")
for portfolio in frontier.portfolios {
	let risk = portfolio.volatility
	let ret = portfolio.expectedReturn
	let sharpe = portfolio.sharpeRatio
	print("\(risk.percent().paddingLeft(toLength: 8)) | \(ret.percent().paddingLeft(toLength: 7)) | \(sharpe.number(3))")
}

// Access optimal portfolios
let minVarPortfolio = frontier.minimumVariancePortfolio
let maxSharpePortfolio = frontier.maximumSharpePortfolio
print("\nMinimum Risk: \(minVarPortfolio.volatility.percent())")
print("Maximum Sharpe: \(maxSharpePortfolio.sharpeRatio.number(3))")
```

#### 4. Risk Parity

Equal risk contribution from each asset.

```swift
let returns = VectorN([0.08, 0.10, 0.12])
let covariance = [
	[0.04, 0.01, 0.02],
	[0.01, 0.09, 0.03],
	[0.02, 0.03, 0.16]
]

let optimizer = PortfolioOptimizer()
let resultRiskParity = try optimizer.riskParityPortfolio(
	expectedReturns: returns,
	covariance: covariance,
	constraintSet: .longOnly
)

print("\n\nRisk Parity Portfolio:")
print("Each asset contributes equally to total risk")
print("Expected Return: \(resultRiskParity.expectedReturn.percent())")
print("Risk: \(resultRiskParity.volatility.percent())")
print()
print("Weights:")
for (i, weight) in resultRiskParity.weights.toArray().enumerated() {
	print("\("Asset \(i)".paddingLeft(toLength: 10)): \(weight.percent(1))")
}

print("Sharpe Ratio: \(resultRiskParity.sharpeRatio.number(2))")
print("Expected Return: \(resultRiskParity.expectedReturn.percent())")
print("Risk (Std Dev): \(resultRiskParity.volatility.percent())")
```

### Common Use Cases

#### Conservative Portfolio (Low Risk)
```swift
let returns = VectorN([0.08, 0.10, 0.12])
let covariance = [
    [0.04, 0.01, 0.02],
    [0.01, 0.09, 0.03],
    [0.02, 0.03, 0.16]
]
let optimizer = PortfolioOptimizer()

// Minimize variance with long-only constraints
let conservative = try optimizer.minimumVariancePortfolio(
    expectedReturns: returns,
    covariance: covariance,
    allowShortSelling: false
)
```

#### Aggressive Portfolio (High Return)
```swift
// Maximum Sharpe with some leverage allowed
let aggressive = try optimizer.maximumSharpePortfolio(
    expectedReturns: returns,
    covariance: covariance,
    riskFreeRate: 0.02,
    constraintSet: .longShort(maxLeverage: 1.5)
)
```

#### Constrained Portfolio (Position Limits)
```swift
// No position > 40%, no position < 5%
let constrained = try optimizer.maximumSharpePortfolio(
    expectedReturns: returns,
    covariance: covariance,
    riskFreeRate: 0.02,
	constraintSet: .boxConstrained(min: 0.05, max: 0.40)
)
```

---

## Integration Examples

### Combining Gradient Descent with Custom Constraints

```swift
// Minimize cost function with custom constraints
let costFunction: (VectorN<Double>) -> Double = { params in
    // Your cost calculation
    return cost
}

// Use gradient descent
let optimizer = MultivariateGradientDescent<VectorN<Double>>()
let result = try optimizer.minimize(
    costFunction,
    from: VectorN([/* initial params */])
)
```

### Parameter Estimation with BFGS

```swift
// Fit parameters to data using least squares
let data: [(x: Double, y: Double)] = [/* your data */]

let leastSquares: (VectorN<Double>) -> Double = { params in
    let a = params[0], b = params[1], c = params[2]

    let errors = data.map { point in
        let predicted = a * point.x * point.x + b * point.x + c
        return (point.y - predicted) * (point.y - predicted)
    }

    return errors.reduce(0, +)  // Sum of squared errors
}

let optimizer = MultivariateNewtonRaphson<VectorN<Double>>()
let result = try optimizer.minimizeBFGS(
    function: leastSquares,
    gradient: { try numericalGradient(leastSquares, at: $0) },
    initialGuess: VectorN([1.0, 1.0, 1.0])
)

print("Best fit parameters: \(result.solution)")
```

---

## Best Practices

### 1. Choose the Right Optimizer

```swift
// Simple, convex problem → Basic GD
let simple = MultivariateGradientDescent<VectorN<Double>>()

// Complex landscape → Gradient Descent with momentum
let complex = GradientDescentOptimizer<Double>(
    learningRate: 0.01,
    momentum: 0.9,
    useNesterov: true
)

// Small dimensions + smooth → BFGS
let smooth = MultivariateNewtonRaphson<VectorN<Double>>()

// Unsure which to use? → Adaptive
let adaptive = AdaptiveOptimizer<VectorN<Double>>()
```

### 2. Scale Your Variables

```swift
// Bad: Variables on different scales
let unscaled = VectorN([1000.0, 0.01, 50.0])

// Good: Normalize to similar ranges
let scaled = VectorN([1.0, 1.0, 1.0])  // Scale externally
```

### 3. Use Good Initial Guesses

```swift
// Bad: Far from solution
let badGuess = VectorN([1000.0, -1000.0])

// Good: Near expected solution
let goodGuess = VectorN([5.0, 3.0])

// Portfolio: Equal weights is often good
let portfolioGuess = VectorN(Array(repeating: 1.0/n, count: n))
```

### 4. Monitor Convergence

```swift
let result = try optimizer.minimize(function, from: initial)

if !result.converged {
    print("Warning: Did not converge in \(result.iterations) iterations")
    print("Final value: \(result.objectiveValue)")
    print("Gradient magnitude: \(result.gradient?.magnitude ?? 0)")
}
```

### 5. Handle Optimization Errors

```swift
do {
    let result = try optimizer.minimize(function, from: initial)
    // Use result
} catch OptimizationError.maxIterationsReached {
    print("Increase maxIterations or adjust tolerance")
} catch OptimizationError.invalidInput(let message) {
    print("Check input: \(message)")
} catch {
    print("Unexpected error: \(error)")
}
```

---

## Summary


This module provides a complete multivariate optimization toolkit:

- **Numerical Differentiation**: Automatic gradients and Hessians
- **Gradient Descent**: Unified optimizer with momentum and Nesterov acceleration
- **Newton-Raphson**: Full Newton and BFGS methods
- **Portfolio Optimization**: Financial applications

**Note:** `GradientDescentOptimizer` is a single, flexible optimizer that supports:
  - Basic gradient descent (momentum = 0.0)
  - Momentum gradient descent (momentum > 0.0, default ≈ 0.8)
  - Nesterov accelerated gradient (useNesterov = true)

**Key Capabilities:**
- Minimize/maximize functions of multiple variables
- Optimize portfolios (min variance, max Sharpe, efficient frontier)
- Fit parameters to data
- Solve systems of equations

**Next Steps:**
1. Try the examples with your own functions
2. Experiment with different optimizers
3. Apply to your specific problems (finance, ML, engineering)
4. Proceed to the next module for constrained optimization

For more information, see source files and test cases.
